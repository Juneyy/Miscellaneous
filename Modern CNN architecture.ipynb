{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYxJAcNh5hHq"
   },
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JKG7bVXm5hHr"
   },
   "source": [
    "### Mount Google Drive\n",
    "\n",
    "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1587613067724,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "gg-gYvo75hHs",
    "outputId": "52e04bc3-53e2-4f08-f255-b0e3a238164a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # --- Mount gdrive to /content/drive/My Drive/\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4pOoRjXS5hH0"
   },
   "source": [
    "Throughout this assignment we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ftz7QLRW5hH2"
   },
   "outputs": [],
   "source": [
    "# --- Set data directory\n",
    "MOUNT_ROOT = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bj1QO0Jq5hH9"
   },
   "source": [
    "### Select Tensorflow library version\n",
    "\n",
    "This assignment will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "voC_af-a5hH_"
   },
   "outputs": [],
   "source": [
    "# --- Select Tensorflow 2.0 (only in Google Colab)\n",
    "% tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pHwekMa5hID"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aq1IUtZ65hIF"
   },
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3948,
     "status": "ok",
     "timestamp": 1587613070871,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "p7Lr_pN75hIF",
    "outputId": "cc615198-a52e-4683-f62a-91362045f355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jarvis-md in /usr/local/lib/python3.6/dist-packages (0.0.1a4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.18.2)\n",
      "Requirement already satisfied: pyyaml>=5.2 in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (5.3.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.21.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (3.2.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2020.4.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->jarvis-md) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RT6Kfif45hIK"
   },
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-hATdeq5hIL"
   },
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers, callbacks\n",
    "from jarvis.train import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjezjATJ5hIP"
   },
   "source": [
    "# Data\n",
    "\n",
    "As in the tutorial, data for this assignment will consist of prostate MRI exams. Each image will consist of one of four different sequences (T2, low b-value DWI, high b-value DWI, ADC). In this initial exercise, the goal is to simply develop an algorith that is capable of differentiating image type so that downstream models for cancer prediction can be used properly. The following lines of code will:\n",
    "\n",
    "1. Download the dataset (if not already present) \n",
    "2. Prepare the necessary Python generators to iterate through dataset\n",
    "3. Prepare the corresponding Tensorflow Input(...) objects for model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BS4vcts5hIQ"
   },
   "outputs": [],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='mr/prostatex')\n",
    "\n",
    "# --- Prepare generators and model inputs\n",
    "configs = {'batch': {'size': 12}}\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex', configs=configs)\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJgj_JNV5hIT"
   },
   "source": [
    "# Training\n",
    "\n",
    "In this assignment we will train a basic convolutional neural network to predict the correct imaging series protocol on prostate MRI. At minumum you must include one of the following modern CNN architecture motifs techniques covered in the tutorial:\n",
    "\n",
    "* residual function with bottleneck operation\n",
    "* Inception module\n",
    "\n",
    "You are also **encouraged** to try different permuations and customizations to achieve optimal validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qsTi3D7c5hIU"
   },
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PodDFn_XAHvj"
   },
   "outputs": [],
   "source": [
    "proj = lambda filters, x, strides : layers.Conv2D(\n",
    "    filters=filters, \n",
    "    strides=strides, \n",
    "    kernel_size=(1, 1),\n",
    "    padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wsfj1k9lAKdn"
   },
   "outputs": [],
   "source": [
    "def residual(a, b):\n",
    "\n",
    "    #Method to implement residual connection between two arbitrary tensors (a + b)\n",
    "\n",
    "    if a[0].shape == b[0].shape:\n",
    "      return a+b\n",
    "    else:\n",
    "      return a+proj(a.shape[3],b,(b.shape[1]/a.shape[1],b.shape[1]/a.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aUCFyEYl4y1P"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preconv = lambda x, filters, strides, kernel_size,  : layers.Conv2D(filters = filters, strides = strides, kernel_size = kernel_size, padding = 'same')(x)\n",
    "\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.LeakyReLU()(x)\n",
    "pool = lambda x : layers.MaxPool2D(pool_size = (3,3), strides = 2, padding = 'same')(x)\n",
    "\n",
    "conv = lambda filters, x, strides: relu(norm(preconv(x,filters, strides, kernel_size = (3,3))))\n",
    "maxpool = lambda x : relu(norm(pool(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1082,
     "status": "ok",
     "timestamp": 1587616148583,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "ZChaEMew5hIV",
    "outputId": "34011774-aaf3-47ea-dd2b-8ba7a471fa7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dat (InputLayer)                [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 256, 256, 256 2560        dat[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 256, 256, 256 1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, 256, 256, 256 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 256, 256, 192 442560      leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 256, 256, 192 768         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, 256, 256, 192 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 256, 256, 168 290472      leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 256, 256, 168 672         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, 256, 256, 168 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 256, 256, 168 43176       leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_13 (TensorFlo [(None, 256, 256, 16 0           leaky_re_lu_56[0][0]             \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 128, 128, 168 0           tf_op_layer_AddV2_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 128, 128, 168 672         max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, 128, 128, 168 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 128, 128, 140 211820      leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 128, 128, 140 560         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, 128, 128, 140 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 64, 64, 140)  0           leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 64, 64, 140)  560         max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, 64, 64, 140)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 64, 64, 108)  136188      leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 64, 64, 108)  432         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, 64, 64, 108)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 64, 64, 108)  18252       tf_op_layer_AddV2_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_14 (TensorFlo [(None, 64, 64, 108) 0           leaky_re_lu_60[0][0]             \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 108)  0           tf_op_layer_AddV2_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 32, 32, 108)  0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 32, 108)  432         max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, 32, 32, 108)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 32, 32, 72)   70056       leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 72)   288         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, 32, 32, 72)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 72)   0           leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 16, 16, 72)   0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 16, 16, 72)   288         max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, 16, 16, 72)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 48)     31152       leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 48)     192         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, 8, 8, 48)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 48)     5232        tf_op_layer_AddV2_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_15 (TensorFlo [(None, 8, 8, 48)]   0           leaky_re_lu_64[0][0]             \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8, 8, 48)     0           tf_op_layer_AddV2_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 4, 4, 48)     0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 4, 4, 48)     192         max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, 4, 4, 48)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 768)          0           leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 4)            3076        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,260,624\n",
      "Trainable params: 1,257,584\n",
      "Non-trainable params: 3,040\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# --- Define model\n",
    "\n",
    "l1 = conv(256, inputs['dat'], 1)\n",
    "l2 = conv(192, l1, 1)\n",
    "l3 = residual(conv(168,l2, 1),l1)\n",
    "l4 = maxpool(l3)\n",
    "l5 = conv(140, l4, 1)\n",
    "l6 = maxpool(l5)\n",
    "l7 = residual(conv(108,l6,1),l3)\n",
    "l7_d = layers.Dropout(0.2)(l7)\n",
    "l8 = maxpool(l7_d)\n",
    "l9 = conv(72,l8,1)\n",
    "l9_d = layers.Dropout(0.2)(l9)\n",
    "l10 = maxpool(l9_d)\n",
    "l11 = residual(conv(48,l10,2),l7)\n",
    "l11_d = layers.Dropout(0.2)(l11)\n",
    "l12 = maxpool(l11_d)\n",
    "\n",
    "\n",
    "f0 = layers.Flatten()(l12)\n",
    "\n",
    "\n",
    "logits = {}\n",
    "logits['class'] = layers.Dense(4, name = 'class')(f0)\n",
    "\n",
    "# --- Create model\n",
    "\n",
    "model = Model(inputs=inputs, outputs=logits)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gk0YgCIh5hIZ"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vtZlHup10Ck"
   },
   "outputs": [],
   "source": [
    "# --- Compile model\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate = 1e-5),\n",
    "    loss={'class': losses.SparseCategoricalCrossentropy(from_logits=True)}, \n",
    "    metrics={'class': 'sparse_categorical_accuracy'},)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qd-vWG5V5hId"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 612894,
     "status": "ok",
     "timestamp": 1587616775696,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "GvRxVXaC5hIe",
    "outputId": "d3f5c966-98ef-48ee-b4cb-d8bdc5195098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.4688 - sparse_categorical_accuracy: 0.3733WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 1.4688 - sparse_categorical_accuracy: 0.3733\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.0435 - sparse_categorical_accuracy: 0.5667WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 1.0435 - sparse_categorical_accuracy: 0.5667\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.7990 - sparse_categorical_accuracy: 0.6917WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.7990 - sparse_categorical_accuracy: 0.6917\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 32s 633ms/step - loss: 0.7278 - sparse_categorical_accuracy: 0.7200 - val_loss: 1.3684 - val_sparse_categorical_accuracy: 0.3233\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5960 - sparse_categorical_accuracy: 0.7917WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.5960 - sparse_categorical_accuracy: 0.7917\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5247 - sparse_categorical_accuracy: 0.8317WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 457ms/step - loss: 0.5247 - sparse_categorical_accuracy: 0.8317\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5145 - sparse_categorical_accuracy: 0.8267WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.5145 - sparse_categorical_accuracy: 0.8267\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 31s 628ms/step - loss: 0.4370 - sparse_categorical_accuracy: 0.8633 - val_loss: 1.2166 - val_sparse_categorical_accuracy: 0.4650\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4451 - sparse_categorical_accuracy: 0.8600WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.4451 - sparse_categorical_accuracy: 0.8600\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3973 - sparse_categorical_accuracy: 0.8633WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.3973 - sparse_categorical_accuracy: 0.8633\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3871 - sparse_categorical_accuracy: 0.8683WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 457ms/step - loss: 0.3871 - sparse_categorical_accuracy: 0.8683\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 31s 628ms/step - loss: 0.3685 - sparse_categorical_accuracy: 0.8733 - val_loss: 0.6761 - val_sparse_categorical_accuracy: 0.8583\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2989 - sparse_categorical_accuracy: 0.9350WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.9350\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3093 - sparse_categorical_accuracy: 0.9067WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.3093 - sparse_categorical_accuracy: 0.9067\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2782 - sparse_categorical_accuracy: 0.9133WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 457ms/step - loss: 0.2782 - sparse_categorical_accuracy: 0.9133\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 31s 629ms/step - loss: 0.2635 - sparse_categorical_accuracy: 0.9067 - val_loss: 0.4175 - val_sparse_categorical_accuracy: 0.9433\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2479 - sparse_categorical_accuracy: 0.9250WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 459ms/step - loss: 0.2479 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2801 - sparse_categorical_accuracy: 0.9150WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.2801 - sparse_categorical_accuracy: 0.9150\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2801 - sparse_categorical_accuracy: 0.9150WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.2801 - sparse_categorical_accuracy: 0.9150\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 31s 628ms/step - loss: 0.2292 - sparse_categorical_accuracy: 0.9300 - val_loss: 0.3338 - val_sparse_categorical_accuracy: 0.9533\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2139 - sparse_categorical_accuracy: 0.9383WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.2139 - sparse_categorical_accuracy: 0.9383\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1988 - sparse_categorical_accuracy: 0.9467WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 457ms/step - loss: 0.1988 - sparse_categorical_accuracy: 0.9467\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1776 - sparse_categorical_accuracy: 0.9433WARNING:tensorflow:Early stopping conditioned on metric `val_sparse_categorical_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n",
      "50/50 [==============================] - 23s 457ms/step - loss: 0.1776 - sparse_categorical_accuracy: 0.9433\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 31s 628ms/step - loss: 0.1969 - sparse_categorical_accuracy: 0.9367 - val_loss: 0.3307 - val_sparse_categorical_accuracy: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3e1998390>"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', restore_best_weights=True)\n",
    "model.fit(\n",
    "    x=gen_train, \n",
    "    steps_per_epoch=50, \n",
    "    epochs=50,\n",
    "    validation_data=gen_valid,\n",
    "    callbacks = callback,\n",
    "    validation_steps=50,\n",
    "    validation_freq=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLrdVkDq5hIj"
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "Based on the tutorial discussion, use the following cells to check your algorithm performance. Consider loading a saved model and running prediction using `model.predict(...)` on the data aggregated via a test generator.\n",
    "\n",
    "**Important**: In this assignment, you must obtain >90% performance accuracy to recieve full credit. Accuracy is determined on a patient by patient (volume by volume) basis, so please *aggregate* results per volume while calculating your performance accuracy here. One common approach is to take the mean prediction across the volume for final prediction; however many altneratives exist. If you determine a better method to calculate accuracy, feel free to implement here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2f3-J265hIj"
   },
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivOO29nj5hIn"
   },
   "source": [
    "**Note**: this cell is used only to check for model performance prior to submission. It will not be graded. Once submitted, your model will be benchmarked against the (same) validation cohort to determine final algorithm performance and grade. If your evaluation code above is correct the algorithm accuracy should match and you can confident that you will recieve full credit for the assignment. Once you are satisfied with your model, proceed to submission of your assignment below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72337,
     "status": "ok",
     "timestamp": 1587616975439,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "uagivWvk5eF4",
    "outputId": "8c37a776-7e4c-4769-ec88-880a696e9434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-04-23 04:42:56 ] [====================] 100.000% : Iterating | 000208    "
     ]
    }
   ],
   "source": [
    "trues = []\n",
    "preds = []\n",
    "\n",
    "for x, y in test_valid:\n",
    "    \n",
    "    # --- Predict\n",
    "    logits = model.predict(x['dat'][0])\n",
    "\n",
    "    if type(logits) is dict:\n",
    "        logits = logits['class']\n",
    "\n",
    "    # --- Argmax\n",
    "    pred = np.argmax(logits, axis=1)\n",
    "\n",
    "    trues.append(y['class'][0, 0])\n",
    "    preds.append(int(np.round(pred.mean())))\n",
    "\n",
    "trues = np.array(trues)\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1587616984444,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "KM9VG4QM5eF9",
    "outputId": "41ebabc4-02b2-40ae-9355-bcc3eb17d54a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9903846153846154\n"
     ]
    }
   ],
   "source": [
    "#--- Create DataFrame\n",
    "df = pd.DataFrame(index=np.arange(preds.size))\n",
    "\n",
    "# --- Define columns\n",
    "df['true'] = trues\n",
    "df['pred'] = preds\n",
    "df['corr'] = df['true'] == df['pred']\n",
    "\n",
    "# --- Print accuracy\n",
    "print(df['corr'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXlsuQBJBP4b"
   },
   "outputs": [],
   "source": [
    "#np.mean(trues == preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqdAqEhD5hIo"
   },
   "source": [
    "### Results\n",
    "\n",
    "When ready, create a `*.csv` file with your compiled **validation** cohort statistics. There is no need to submit training performance accuracy. As in the tutorial, ensure that there are at least three columns in the `*.csv` file:\n",
    "\n",
    "* true (ground-truth)\n",
    "* pred (prediction)\n",
    "* corr (correction prediction, True or False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08dhnZn45hIp"
   },
   "outputs": [],
   "source": [
    "# --- Create *.csv\n",
    "                              \n",
    "# --- Serialize *.csv\n",
    "fname = '{}/models/series_id/results.csv'.format(MOUNT_ROOT)\n",
    "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "df.to_csv('assignment_4')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment 4.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/peterchang77/dl_tutor/blob/master/cs190/notebooks/series_id/assignment.ipynb",
     "timestamp": 1587592705929
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
