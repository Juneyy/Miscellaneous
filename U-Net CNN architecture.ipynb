{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWg3WUWU9pQG"
   },
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgYnpAg29pQG"
   },
   "source": [
    "### Mount Google Drive\n",
    "\n",
    "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30437,
     "status": "ok",
     "timestamp": 1589307829431,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "LyRqGyR_9pQJ",
    "outputId": "4957b26b-6ca8-40d8-eb1e-075503c7daa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # --- Mount gdrive to /content/drive/My Drive/\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wm__J3Xl9pQQ"
   },
   "source": [
    "Throughout this assignment we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lywvB839pQR"
   },
   "outputs": [],
   "source": [
    "# --- Set data directory\n",
    "MOUNT_ROOT = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRgmAKLK9pQW"
   },
   "source": [
    "### Select Tensorflow library version\n",
    "\n",
    "This assignment will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5omlTFhi9pQY"
   },
   "outputs": [],
   "source": [
    "# --- Select Tensorflow 2.0 (only in Google Colab)\n",
    "% tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUGOUdHE9pQc"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "inkaUVzq9pQe"
   },
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7947,
     "status": "ok",
     "timestamp": 1589307837522,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "efPcDP449pQf",
    "outputId": "25568233-67fe-411a-89cc-b09df09f44db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jarvis-md\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/de/f5d39bfb27c0af58de808a5ee4da4d1c883444c1c6d4b4c53df89ad9612e/jarvis_md-0.0.1a6-py3-none-any.whl (59kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.18.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.23.0)\n",
      "Collecting pyyaml>=5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 7.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.0.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (3.2.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2018.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->jarvis-md) (1.12.0)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=b370866dda7acd05b4194ef671eaa500210258ce7a9cf2bb5d65a199ef983241\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, jarvis-md\n",
      "  Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed jarvis-md-0.0.1a6 pyyaml-5.3.1\n"
     ]
    }
   ],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "678GUka_9pQk"
   },
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4M3OnHd9pQk"
   },
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers, callbacks\n",
    "from jarvis.train import datasets, custom\n",
    "from jarvis.utils.display import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CO7Qg_UT9pQo"
   },
   "source": [
    "# Data\n",
    "\n",
    "As in the tutorial, data for this assignment will consist of prostate MRI exams. In prior work, an algorithm was created to separate out different MRI sequences. In this current assignment, only T2-weighted images (isolated using the prior algorithm) will be used for segmentation. In prostate imaging, the T2-weighted sequence captures the greatest amount of anatomic detail and is thus ideal for delineation of prostate gland structures.\n",
    "\n",
    "The following lines of code will download the dataset (if not already present). Since each algorithm below requires a different dataset, the required generators and inputs will be defined dyanically in the code blocks later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31090,
     "status": "ok",
     "timestamp": 1589307860676,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "_JNCUDsU9pQp",
    "outputId": "aabc7421-2718-4fb8-f217-1c3931c47afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-12 18:24:19 ] [====================] 100.000% : Extracting archive (0001380 / 0001380) "
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'code': '/data/raw/mr_prostatex_seg', 'data': '/data/raw/mr_prostatex_seg'}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='mr/prostatex-seg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZO8mDnNA9pQt"
   },
   "source": [
    "# Training\n",
    "\n",
    "A total of three different network architectures will be tested. The goal is to compare the incremental benefit of several design choices. After building and training each model to convergence, do not forget to save each model as a separate `*.hdf5` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6YYd9WE9pQu"
   },
   "source": [
    "## 1. 2D U-Net (single step)\n",
    "\n",
    "In this algorithm a standard 2D U-Net architecture will be used to perform prostate segmentation. This network is **identical** to the week 5 assignment. The algorithm input will include an entire full field-of-view `256 x 256` resolution 2D slice from a T2 weighted MR image. Key customizations to the standard U-Net architecture that should be implemented (as in the week 5 assignment) include:\n",
    "\n",
    "* same padding (vs. valid padding)\n",
    "* strided convolutions (vs. max-pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NDig4U6q9pQv"
   },
   "source": [
    "### Create generators and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVvq5Uv79pQv"
   },
   "outputs": [],
   "source": [
    "# --- Original 256 x 256 (one-step)\n",
    "configs = {'batch': {'size': 12}}\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', keyword='seg-256',configs = {'batch': {'size': 12}})\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Coxf6HeaDYXq"
   },
   "outputs": [],
   "source": [
    "xs, ys= next(gen_train)\n",
    "imshow(xs['dat'], ys['zones'], figsize=(12, 12))\n",
    "print(ys['zones'].shape)\n",
    "print(inputs['dat'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CXoto4929pQz"
   },
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tavkn9EW9CKZ"
   },
   "outputs": [],
   "source": [
    "kwargs_1 = {\n",
    "    'kernel_size': (1,3,3),\n",
    "    'padding': 'same'\n",
    "}\n",
    "\n",
    "convolution = lambda x, filters, strides: layers.Conv3D(filters = filters, strides = strides, **kwargs_1)(x)\n",
    "norm = lambda x: layers.BatchNormalization()(x)\n",
    "relu = lambda x: layers.LeakyReLU()(x)\n",
    "\n",
    "conv1 = lambda filters, x: relu(norm(convolution(x, filters, strides = (1,1,1))))\n",
    "conv2 = lambda filters, x: relu(norm(convolution(x, filters, strides = (1,2,2))))\n",
    "\n",
    "\n",
    "concat = lambda a,b: layers.Concatenate()([a,b])\n",
    "\n",
    "tran = lambda x, filters, strides: layers.Conv3DTranspose(filters = filters, strides = strides, **kwargs_1)(x)\n",
    "\n",
    "tran2 = lambda filters, x: relu(norm(tran(x, filters, strides=(1, 2, 2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9286,
     "status": "ok",
     "timestamp": 1589307869983,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "BCzCq2rd9pQ0",
    "outputId": "879d0591-dc39-4a6a-f144-aa5089566d55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dat (InputLayer)                [(None, None, 256, 2 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, None, 256, 25 80          dat[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 256, 25 32          conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, None, 256, 25 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, None, 128, 12 1168        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 128, 12 64          conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, 128, 12 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, None, 128, 12 2320        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 128, 12 64          conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, 128, 12 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, None, 64, 64, 4640        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 64, 64, 128         conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, 64, 64, 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, None, 64, 64, 9248        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, 64, 64, 128         conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, 64, 64, 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, None, 32, 32, 18496       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, 32, 32, 256         conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, None, 32, 32, 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, None, 32, 32, 36928       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, 32, 32, 256         conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, None, 32, 32, 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, None, 16, 16, 73856       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, 16, 16, 512         conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, None, 16, 16, 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, None, 16, 16, 147584      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, 16, 16, 512         conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, None, 16, 16, 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose (Conv3DTranspo (None, None, 32, 32, 73792       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, 32, 32, 256         conv3d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, None, 32, 32, 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 32, 32, 0           leaky_re_lu_9[0][0]              \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, None, 32, 32, 73792       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, 32, 32, 256         conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTrans (None, None, 64, 64, 18464       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, 64, 64, 128         conv3d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 64, 64, 0           leaky_re_lu_11[0][0]             \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, None, 64, 64, 18464       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, 64, 64, 128         conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTrans (None, None, 128, 12 4624        leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, 128, 12 64          conv3d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, None, 128, 12 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 128, 12 0           leaky_re_lu_13[0][0]             \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, None, 128, 12 4624        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, 128, 12 64          conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, None, 128, 12 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTrans (None, None, 256, 25 1160        leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, 256, 25 32          conv3d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, None, 256, 25 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, None, 256, 2 0           leaky_re_lu_15[0][0]             \n",
      "                                                                 dat[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, None, 256, 25 584         tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, 256, 25 32          conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, None, 256, 25 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zones (Conv3D)                  (None, None, 256, 25 219         leaky_re_lu_16[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 492,955\n",
      "Trainable params: 491,499\n",
      "Non-trainable params: 1,456\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# --- Define model\n",
    "l1 = conv1(8, inputs['dat'])  #the first layer doesnt go down. It gets the 8 nodes\n",
    "l2 = conv1(16, conv2(16,l1))\n",
    "l3 = conv1(32, conv2(32,l2))\n",
    "l4 = conv1(64, conv2(64,l3))\n",
    "l5 = conv1(128, conv2(128,l4))\n",
    "l6 = tran2(64, l5)\n",
    "l7 = tran2(32, conv1(64, concat(l6, l4)))\n",
    "l8 = tran2(16, conv1(32, concat(l7, l3)))\n",
    "l9 = tran2(8, conv1(16, concat(l8, l2)))\n",
    "l10 = conv1(8, l9 + inputs['dat'] )\n",
    "\n",
    "# --- Create logits\n",
    "logits = {}\n",
    "logits['zones'] = layers.Conv3D(filters=3, kernel_size = (1,3,3), name='zones', padding = 'same')(l10)\n",
    "\n",
    "# --- Create model\n",
    "model = Model(inputs=inputs, outputs=logits)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7uINMFxx9pQ5"
   },
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3250826,
     "status": "ok",
     "timestamp": 1589311111533,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "mao_kHZS9pQ6",
    "outputId": "b26a0e4f-3046-4b69-cff0-9d9dec467708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-12 18:24:40 ] [====================] 100.000% : Iterating | 000342    Epoch 1/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9872 - dsc_1: 0.0585 - dsc_2: 0.0055WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.9872 - dsc_1: 0.0585 - dsc_2: 0.0055\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6048 - dsc_1: 0.3041 - dsc_2: 6.0399e-04WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.6048 - dsc_1: 0.3041 - dsc_2: 6.0399e-04\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3687 - dsc_1: 0.5669 - dsc_2: 0.0390WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.3687 - dsc_1: 0.5669 - dsc_2: 0.0390\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.2276 - dsc_1: 0.6752 - dsc_2: 0.2354 - val_loss: 0.2305 - val_dsc_1: 0.6497 - val_dsc_2: 0.2825\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1476 - dsc_1: 0.7590 - dsc_2: 0.4768WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.1476 - dsc_1: 0.7590 - dsc_2: 0.4768\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1052 - dsc_1: 0.7862 - dsc_2: 0.5272WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.1052 - dsc_1: 0.7862 - dsc_2: 0.5272\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0781 - dsc_1: 0.8087 - dsc_2: 0.5573WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0781 - dsc_1: 0.8087 - dsc_2: 0.5573\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.0627 - dsc_1: 0.8278 - dsc_2: 0.5962 - val_loss: 0.0675 - val_dsc_1: 0.8218 - val_dsc_2: 0.5925\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0529 - dsc_1: 0.8227 - dsc_2: 0.6043WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0529 - dsc_1: 0.8227 - dsc_2: 0.6043\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0436 - dsc_1: 0.8587 - dsc_2: 0.6363WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0436 - dsc_1: 0.8587 - dsc_2: 0.6363\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0396 - dsc_1: 0.8454 - dsc_2: 0.6353WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0396 - dsc_1: 0.8454 - dsc_2: 0.6353\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 61s 613ms/step - loss: 0.0363 - dsc_1: 0.8534 - dsc_2: 0.6506 - val_loss: 0.0386 - val_dsc_1: 0.8647 - val_dsc_2: 0.6156\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0328 - dsc_1: 0.8624 - dsc_2: 0.6494WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0328 - dsc_1: 0.8624 - dsc_2: 0.6494\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0304 - dsc_1: 0.8598 - dsc_2: 0.6639WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0304 - dsc_1: 0.8598 - dsc_2: 0.6639\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0279 - dsc_1: 0.8763 - dsc_2: 0.6760WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0279 - dsc_1: 0.8763 - dsc_2: 0.6760\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.0271 - dsc_1: 0.8742 - dsc_2: 0.6734 - val_loss: 0.0281 - val_dsc_1: 0.8679 - val_dsc_2: 0.6559\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0259 - dsc_1: 0.8747 - dsc_2: 0.6807WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0259 - dsc_1: 0.8747 - dsc_2: 0.6807\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0238 - dsc_1: 0.8757 - dsc_2: 0.6747WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0238 - dsc_1: 0.8757 - dsc_2: 0.6747\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0235 - dsc_1: 0.8875 - dsc_2: 0.6889WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0235 - dsc_1: 0.8875 - dsc_2: 0.6889\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.0224 - dsc_1: 0.8810 - dsc_2: 0.6984 - val_loss: 0.0251 - val_dsc_1: 0.8781 - val_dsc_2: 0.6514\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0223 - dsc_1: 0.8847 - dsc_2: 0.6863WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0223 - dsc_1: 0.8847 - dsc_2: 0.6863\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0211 - dsc_1: 0.8874 - dsc_2: 0.7075WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0211 - dsc_1: 0.8874 - dsc_2: 0.7075\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0202 - dsc_1: 0.8851 - dsc_2: 0.6923WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0202 - dsc_1: 0.8851 - dsc_2: 0.6923\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 62s 619ms/step - loss: 0.0189 - dsc_1: 0.8910 - dsc_2: 0.7143 - val_loss: 0.0222 - val_dsc_1: 0.8902 - val_dsc_2: 0.6711\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0196 - dsc_1: 0.8926 - dsc_2: 0.7039WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0196 - dsc_1: 0.8926 - dsc_2: 0.7039\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0186 - dsc_1: 0.8913 - dsc_2: 0.7148WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0186 - dsc_1: 0.8913 - dsc_2: 0.7148\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0190 - dsc_1: 0.8964 - dsc_2: 0.7207WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0190 - dsc_1: 0.8964 - dsc_2: 0.7207\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.0176 - dsc_1: 0.8977 - dsc_2: 0.7238 - val_loss: 0.0210 - val_dsc_1: 0.8928 - val_dsc_2: 0.6822\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0168 - dsc_1: 0.9037 - dsc_2: 0.7283WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0168 - dsc_1: 0.9037 - dsc_2: 0.7283\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0175 - dsc_1: 0.9019 - dsc_2: 0.7245WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0175 - dsc_1: 0.9019 - dsc_2: 0.7245\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0169 - dsc_1: 0.9020 - dsc_2: 0.7244WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0169 - dsc_1: 0.9020 - dsc_2: 0.7244\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 62s 615ms/step - loss: 0.0171 - dsc_1: 0.8947 - dsc_2: 0.7357 - val_loss: 0.0215 - val_dsc_1: 0.8774 - val_dsc_2: 0.6838\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0161 - dsc_1: 0.9027 - dsc_2: 0.7328WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0161 - dsc_1: 0.9027 - dsc_2: 0.7328\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0156 - dsc_1: 0.9090 - dsc_2: 0.7396WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0156 - dsc_1: 0.9090 - dsc_2: 0.7396\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0158 - dsc_1: 0.9018 - dsc_2: 0.7482WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0158 - dsc_1: 0.9018 - dsc_2: 0.7482\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 61s 615ms/step - loss: 0.0165 - dsc_1: 0.9078 - dsc_2: 0.7425 - val_loss: 0.0206 - val_dsc_1: 0.8854 - val_dsc_2: 0.6928\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0160 - dsc_1: 0.9007 - dsc_2: 0.7303WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0160 - dsc_1: 0.9007 - dsc_2: 0.7303\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0144 - dsc_1: 0.9083 - dsc_2: 0.7562WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0144 - dsc_1: 0.9083 - dsc_2: 0.7562\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0148 - dsc_1: 0.9125 - dsc_2: 0.7445WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0148 - dsc_1: 0.9125 - dsc_2: 0.7445\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 0.0151 - dsc_1: 0.9057 - dsc_2: 0.7532 - val_loss: 0.0193 - val_dsc_1: 0.8967 - val_dsc_2: 0.6864\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0150 - dsc_1: 0.9102 - dsc_2: 0.7481WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0150 - dsc_1: 0.9102 - dsc_2: 0.7481\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0149 - dsc_1: 0.9068 - dsc_2: 0.7402WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0149 - dsc_1: 0.9068 - dsc_2: 0.7402\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0141 - dsc_1: 0.9137 - dsc_2: 0.7589WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0141 - dsc_1: 0.9137 - dsc_2: 0.7589\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 61s 615ms/step - loss: 0.0133 - dsc_1: 0.9108 - dsc_2: 0.7653 - val_loss: 0.0194 - val_dsc_1: 0.8985 - val_dsc_2: 0.6828\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0143 - dsc_1: 0.9143 - dsc_2: 0.7546WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0143 - dsc_1: 0.9143 - dsc_2: 0.7546\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0145 - dsc_1: 0.9102 - dsc_2: 0.7577WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0145 - dsc_1: 0.9102 - dsc_2: 0.7577\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0136 - dsc_1: 0.9114 - dsc_2: 0.7708WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0136 - dsc_1: 0.9114 - dsc_2: 0.7708\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.0134 - dsc_1: 0.9178 - dsc_2: 0.7733 - val_loss: 0.0229 - val_dsc_1: 0.8690 - val_dsc_2: 0.6708\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0138 - dsc_1: 0.9144 - dsc_2: 0.7594WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0138 - dsc_1: 0.9144 - dsc_2: 0.7594\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0138 - dsc_1: 0.9149 - dsc_2: 0.7637WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0138 - dsc_1: 0.9149 - dsc_2: 0.7637\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0138 - dsc_1: 0.9099 - dsc_2: 0.7616WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0138 - dsc_1: 0.9099 - dsc_2: 0.7616\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 61s 613ms/step - loss: 0.0125 - dsc_1: 0.9224 - dsc_2: 0.7811 - val_loss: 0.0196 - val_dsc_1: 0.8928 - val_dsc_2: 0.6856\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0136 - dsc_1: 0.9154 - dsc_2: 0.7728WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0136 - dsc_1: 0.9154 - dsc_2: 0.7728\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0128 - dsc_1: 0.9202 - dsc_2: 0.7781WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0128 - dsc_1: 0.9202 - dsc_2: 0.7781\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0126 - dsc_1: 0.9173 - dsc_2: 0.7729WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0126 - dsc_1: 0.9173 - dsc_2: 0.7729\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 61s 613ms/step - loss: 0.0124 - dsc_1: 0.9189 - dsc_2: 0.7797 - val_loss: 0.0202 - val_dsc_1: 0.8920 - val_dsc_2: 0.6781\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0116 - dsc_1: 0.9208 - dsc_2: 0.7948WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0116 - dsc_1: 0.9208 - dsc_2: 0.7948\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0121 - dsc_1: 0.9234 - dsc_2: 0.7825WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0121 - dsc_1: 0.9234 - dsc_2: 0.7825\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0124 - dsc_1: 0.9207 - dsc_2: 0.7770WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0124 - dsc_1: 0.9207 - dsc_2: 0.7770\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 0.0127 - dsc_1: 0.9218 - dsc_2: 0.7821 - val_loss: 0.0190 - val_dsc_1: 0.8991 - val_dsc_2: 0.7118\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0116 - dsc_1: 0.9234 - dsc_2: 0.7950WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0116 - dsc_1: 0.9234 - dsc_2: 0.7950\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0115 - dsc_1: 0.9240 - dsc_2: 0.7972WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0115 - dsc_1: 0.9240 - dsc_2: 0.7972\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0119 - dsc_1: 0.9267 - dsc_2: 0.7895WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0119 - dsc_1: 0.9267 - dsc_2: 0.7895\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 61s 615ms/step - loss: 0.0117 - dsc_1: 0.9223 - dsc_2: 0.7968 - val_loss: 0.0203 - val_dsc_1: 0.8935 - val_dsc_2: 0.6704\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0118 - dsc_1: 0.9258 - dsc_2: 0.7931WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0118 - dsc_1: 0.9258 - dsc_2: 0.7931\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0112 - dsc_1: 0.9301 - dsc_2: 0.8077WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0112 - dsc_1: 0.9301 - dsc_2: 0.8077\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0110 - dsc_1: 0.9293 - dsc_2: 0.8021WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0110 - dsc_1: 0.9293 - dsc_2: 0.8021\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 0.0109 - dsc_1: 0.9283 - dsc_2: 0.7964 - val_loss: 0.0206 - val_dsc_1: 0.8954 - val_dsc_2: 0.6811\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0121 - dsc_1: 0.9214 - dsc_2: 0.7850WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0121 - dsc_1: 0.9214 - dsc_2: 0.7850\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0109 - dsc_1: 0.9309 - dsc_2: 0.8122WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0109 - dsc_1: 0.9309 - dsc_2: 0.8122\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0100 - dsc_1: 0.9311 - dsc_2: 0.8149WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0100 - dsc_1: 0.9311 - dsc_2: 0.8149\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 0.0106 - dsc_1: 0.9292 - dsc_2: 0.8141 - val_loss: 0.0195 - val_dsc_1: 0.8979 - val_dsc_2: 0.7006\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0110 - dsc_1: 0.9286 - dsc_2: 0.8071WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0110 - dsc_1: 0.9286 - dsc_2: 0.8071\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0110 - dsc_1: 0.9282 - dsc_2: 0.7951WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0110 - dsc_1: 0.9282 - dsc_2: 0.7951\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0101 - dsc_1: 0.9328 - dsc_2: 0.8142WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0101 - dsc_1: 0.9328 - dsc_2: 0.8142\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 61s 612ms/step - loss: 0.0099 - dsc_1: 0.9357 - dsc_2: 0.8224 - val_loss: 0.0206 - val_dsc_1: 0.8961 - val_dsc_2: 0.6908\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0105 - dsc_1: 0.9345 - dsc_2: 0.8177WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0105 - dsc_1: 0.9345 - dsc_2: 0.8177\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0103 - dsc_1: 0.9326 - dsc_2: 0.8103WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0103 - dsc_1: 0.9326 - dsc_2: 0.8103\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0105 - dsc_1: 0.9300 - dsc_2: 0.8180WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0105 - dsc_1: 0.9300 - dsc_2: 0.8180\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 0.0101 - dsc_1: 0.9363 - dsc_2: 0.8226 - val_loss: 0.0230 - val_dsc_1: 0.8939 - val_dsc_2: 0.6284\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0097 - dsc_1: 0.9339 - dsc_2: 0.8233WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0097 - dsc_1: 0.9339 - dsc_2: 0.8233\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0101 - dsc_1: 0.9349 - dsc_2: 0.8221WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0101 - dsc_1: 0.9349 - dsc_2: 0.8221\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0100 - dsc_1: 0.9287 - dsc_2: 0.8179WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0100 - dsc_1: 0.9287 - dsc_2: 0.8179\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 0.0098 - dsc_1: 0.9355 - dsc_2: 0.8199 - val_loss: 0.0214 - val_dsc_1: 0.8947 - val_dsc_2: 0.6859\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0098 - dsc_1: 0.9359 - dsc_2: 0.8271WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0098 - dsc_1: 0.9359 - dsc_2: 0.8271\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0095 - dsc_1: 0.9347 - dsc_2: 0.8271WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0095 - dsc_1: 0.9347 - dsc_2: 0.8271\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0096 - dsc_1: 0.9356 - dsc_2: 0.8210WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0096 - dsc_1: 0.9356 - dsc_2: 0.8210\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 61s 614ms/step - loss: 0.0094 - dsc_1: 0.9403 - dsc_2: 0.8274 - val_loss: 0.0204 - val_dsc_1: 0.8988 - val_dsc_2: 0.6933\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0092 - dsc_1: 0.9411 - dsc_2: 0.8399WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0092 - dsc_1: 0.9411 - dsc_2: 0.8399\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0090 - dsc_1: 0.9383 - dsc_2: 0.8295WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0090 - dsc_1: 0.9383 - dsc_2: 0.8295\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0091 - dsc_1: 0.9410 - dsc_2: 0.8321WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0091 - dsc_1: 0.9410 - dsc_2: 0.8321\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 61s 615ms/step - loss: 0.0095 - dsc_1: 0.9387 - dsc_2: 0.8322 - val_loss: 0.0206 - val_dsc_1: 0.8999 - val_dsc_2: 0.7016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7101e19b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Compile model\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
    "    loss = {'zones': losses.SparseCategoricalCrossentropy(from_logits = True)},\n",
    "    metrics = {'zones': custom.dsc(cls=2)},\n",
    "     experimental_run_tf_function=False\n",
    ")\n",
    "\n",
    "client.load_data_in_memory()\n",
    "\n",
    "callback = callbacks.EarlyStopping(monitor='val_dsc_2', patience = 8, restore_best_weights=True, mode= 'max')\n",
    "# --- Train the model\n",
    "model.fit(\n",
    "    x = gen_train,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 100,\n",
    "    validation_data = gen_valid,\n",
    "    validation_steps = 500,\n",
    "    validation_freq = 4,\n",
    "#    use_muiltiprocessing = True,\n",
    "    callbacks = callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hLgLCxQH9pQ9"
   },
   "source": [
    "## 2. 2D U-Net (multiple step)\n",
    "\n",
    "In this algorithm, the output of the first 2D U-Net will be used to generated a cropped `128 x 128` resolution 2D slice centered around the prostate gland. This method effectively focuses the algorithm field-of-view to the area of interest and helps improve on inherent class imbalance associated with this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLxsa3LG9pQ9"
   },
   "source": [
    "### Create generators and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlyM1I049pRA"
   },
   "outputs": [],
   "source": [
    "# --- Cropped 128 x 128 (multiple step)\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', keyword='seg-crp', configs = {'batch': {'size': 12}})\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3sIR-ss9m99r"
   },
   "outputs": [],
   "source": [
    "xs, ys= next(gen_train)\n",
    "imshow(xs['dat'], ys['zones'], figsize=(12, 12))\n",
    "print(ys['zones'].shape)\n",
    "print(inputs['dat'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TvOVAwUs9pRD"
   },
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3252758,
     "status": "ok",
     "timestamp": 1589311113477,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "bueJsnh-9pRD",
    "outputId": "5e4791e6-b654-41e9-db07-0bdb0d120eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dat (InputLayer)                [(None, None, 128, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, None, 128, 12 40          dat[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, 128, 12 16          conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, None, 128, 12 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, None, 64, 64, 148         leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, 64, 64, 16          conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, None, 64, 64, 296         leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, 64, 64, 32          conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, None, 32, 32, 584         leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, 32, 32, 32          conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, None, 32, 32, 1168        leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, 32, 32, 64          conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, None, 16, 16, 2320        leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, 16, 16, 64          conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, None, 16, 16, 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, None, 16, 16, 4640        leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, 16, 16, 128         conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, None, 16, 16, 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, None, 8, 8, 3 9248        leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, 8, 8, 3 128         conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, None, 8, 8, 3 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, None, 8, 8, 6 18496       leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, 8, 8, 6 256         conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, None, 8, 8, 6 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_4 (Conv3DTrans (None, None, 16, 16, 18464       leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, 16, 16, 128         conv3d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, None, 16, 16, 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 16, 16, 0           leaky_re_lu_26[0][0]             \n",
      "                                                                 leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, None, 16, 16, 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, 16, 16, 128         conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, None, 16, 16, 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_5 (Conv3DTrans (None, None, 32, 32, 4624        leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, 32, 32, 64          conv3d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, 32, 32, 0           leaky_re_lu_28[0][0]             \n",
      "                                                                 leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, None, 32, 32, 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, 32, 32, 64          conv3d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_6 (Conv3DTrans (None, None, 64, 64, 1160        leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, 64, 64, 32          conv3d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, 64, 64, 0           leaky_re_lu_30[0][0]             \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)              (None, None, 64, 64, 1160        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, 64, 64, 32          conv3d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_7 (Conv3DTrans (None, None, 128, 12 292         leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, 128, 12 16          conv3d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, None, 128, 12 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, 128, 12 0           leaky_re_lu_32[0][0]             \n",
      "                                                                 dat[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)              (None, None, 128, 12 184         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, 128, 12 16          conv3d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, None, 128, 12 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zones (Conv3D)                  (None, None, 128, 12 111         leaky_re_lu_33[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 87,239\n",
      "Trainable params: 86,631\n",
      "Non-trainable params: 608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# --- Define model\n",
    "\n",
    "#l1_2step = conv1(4 , inputs['dat']) #the first layer doesnt go down. It gets the 8 nodes\n",
    "l2_2step = conv1(4, inputs['dat'])\n",
    "l3_2step = conv1(8, conv2(4,l2_2step))\n",
    "l4_2step = conv1(16, conv2(8,l3_2step))\n",
    "l5_2step = conv1(32, conv2(16,l4_2step))\n",
    "l6_2step = conv1(64, conv2(32,l5_2step))\n",
    "\n",
    "\n",
    "l7_2step = tran2(32, l6_2step)\n",
    "l8_2step = tran2(16, conv1(32, concat(l7_2step, l5_2step)))\n",
    "l9_2step = tran2(8, conv1(16, concat(l8_2step, l4_2step)))\n",
    "\n",
    "l10_2step = tran2(4, conv1(8, concat(l9_2step, l3_2step)))\n",
    "#l11_2step = tran2(4, conv1(32, concat(l10_2step, l2_2step)))\n",
    "l11_2step = conv1(4, concat(l10_2step, inputs['dat']))\n",
    "# --- Create logits\n",
    "\n",
    "logits_2step = {}\n",
    "logits_2step['zones'] = layers.Conv3D(filters=3, kernel_size = (1,3,3), name='zones', padding = 'same')(l11_2step)\n",
    "\n",
    "# --- Create model\n",
    "model2 = Model(inputs=inputs, outputs=logits_2step)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Rj_Uniw9pRG"
   },
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4608509,
     "status": "ok",
     "timestamp": 1589312469239,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "hrXbCSbD9pRH",
    "outputId": "30d12b66-da87-4ff9-e1b3-531bdbf7acba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-12 19:18:35 ] [====================] 100.000% : Iterating | 000342    Epoch 1/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.9008 - dsc_1: 0.4840 - dsc_2: 0.0758WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.9008 - dsc_1: 0.4840 - dsc_2: 0.0758\n",
      "Epoch 2/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5106 - dsc_1: 0.6873 - dsc_2: 0.1642WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.5106 - dsc_1: 0.6873 - dsc_2: 0.1642\n",
      "Epoch 3/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3359 - dsc_1: 0.7714 - dsc_2: 0.4286WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.3359 - dsc_1: 0.7714 - dsc_2: 0.4286\n",
      "Epoch 4/200\n",
      "150/150 [==============================] - 20s 135ms/step - loss: 0.2624 - dsc_1: 0.7930 - dsc_2: 0.5304 - val_loss: 0.2317 - val_dsc_1: 0.8003 - val_dsc_2: 0.5513\n",
      "Epoch 5/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2097 - dsc_1: 0.8295 - dsc_2: 0.5886WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.2097 - dsc_1: 0.8295 - dsc_2: 0.5886\n",
      "Epoch 6/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1843 - dsc_1: 0.8338 - dsc_2: 0.6180WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 58ms/step - loss: 0.1843 - dsc_1: 0.8338 - dsc_2: 0.6180\n",
      "Epoch 7/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1674 - dsc_1: 0.8377 - dsc_2: 0.6325WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1674 - dsc_1: 0.8377 - dsc_2: 0.6325\n",
      "Epoch 8/200\n",
      "150/150 [==============================] - 20s 131ms/step - loss: 0.1557 - dsc_1: 0.8465 - dsc_2: 0.6394 - val_loss: 0.1542 - val_dsc_1: 0.8425 - val_dsc_2: 0.6376\n",
      "Epoch 9/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1469 - dsc_1: 0.8531 - dsc_2: 0.6466WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.1469 - dsc_1: 0.8531 - dsc_2: 0.6466\n",
      "Epoch 10/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1395 - dsc_1: 0.8556 - dsc_2: 0.6659WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.1395 - dsc_1: 0.8556 - dsc_2: 0.6659\n",
      "Epoch 11/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1320 - dsc_1: 0.8597 - dsc_2: 0.6715WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1320 - dsc_1: 0.8597 - dsc_2: 0.6715\n",
      "Epoch 12/200\n",
      "150/150 [==============================] - 19s 130ms/step - loss: 0.1274 - dsc_1: 0.8664 - dsc_2: 0.6715 - val_loss: 0.1280 - val_dsc_1: 0.8590 - val_dsc_2: 0.6530\n",
      "Epoch 13/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1247 - dsc_1: 0.8710 - dsc_2: 0.6876WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1247 - dsc_1: 0.8710 - dsc_2: 0.6876\n",
      "Epoch 14/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1184 - dsc_1: 0.8764 - dsc_2: 0.6896WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1184 - dsc_1: 0.8764 - dsc_2: 0.6896\n",
      "Epoch 15/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1157 - dsc_1: 0.8719 - dsc_2: 0.7033WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1157 - dsc_1: 0.8719 - dsc_2: 0.7033\n",
      "Epoch 16/200\n",
      "150/150 [==============================] - 19s 129ms/step - loss: 0.1185 - dsc_1: 0.8692 - dsc_2: 0.6965 - val_loss: 0.1136 - val_dsc_1: 0.8719 - val_dsc_2: 0.6838\n",
      "Epoch 17/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1094 - dsc_1: 0.8834 - dsc_2: 0.7030WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1094 - dsc_1: 0.8834 - dsc_2: 0.7030\n",
      "Epoch 18/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1094 - dsc_1: 0.8841 - dsc_2: 0.7076WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1094 - dsc_1: 0.8841 - dsc_2: 0.7076\n",
      "Epoch 19/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1096 - dsc_1: 0.8799 - dsc_2: 0.7127WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1096 - dsc_1: 0.8799 - dsc_2: 0.7127\n",
      "Epoch 20/200\n",
      "150/150 [==============================] - 20s 130ms/step - loss: 0.1079 - dsc_1: 0.8827 - dsc_2: 0.7109 - val_loss: 0.1204 - val_dsc_1: 0.8653 - val_dsc_2: 0.6688\n",
      "Epoch 21/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1033 - dsc_1: 0.8920 - dsc_2: 0.7230WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1033 - dsc_1: 0.8920 - dsc_2: 0.7230\n",
      "Epoch 22/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1055 - dsc_1: 0.8860 - dsc_2: 0.7194WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.1055 - dsc_1: 0.8860 - dsc_2: 0.7194\n",
      "Epoch 23/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1017 - dsc_1: 0.8862 - dsc_2: 0.7216WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.1017 - dsc_1: 0.8862 - dsc_2: 0.7216\n",
      "Epoch 24/200\n",
      "150/150 [==============================] - 19s 130ms/step - loss: 0.1016 - dsc_1: 0.8891 - dsc_2: 0.7270 - val_loss: 0.1041 - val_dsc_1: 0.8898 - val_dsc_2: 0.7018\n",
      "Epoch 25/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1003 - dsc_1: 0.8890 - dsc_2: 0.7324WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.1003 - dsc_1: 0.8890 - dsc_2: 0.7324\n",
      "Epoch 26/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0987 - dsc_1: 0.8930 - dsc_2: 0.7246WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0987 - dsc_1: 0.8930 - dsc_2: 0.7246\n",
      "Epoch 27/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0944 - dsc_1: 0.8958 - dsc_2: 0.7441WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0944 - dsc_1: 0.8958 - dsc_2: 0.7441\n",
      "Epoch 28/200\n",
      "150/150 [==============================] - 20s 132ms/step - loss: 0.1000 - dsc_1: 0.8889 - dsc_2: 0.7344 - val_loss: 0.0994 - val_dsc_1: 0.8885 - val_dsc_2: 0.7099\n",
      "Epoch 29/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0949 - dsc_1: 0.8952 - dsc_2: 0.7331WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0949 - dsc_1: 0.8952 - dsc_2: 0.7331\n",
      "Epoch 30/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0931 - dsc_1: 0.8959 - dsc_2: 0.7373WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0931 - dsc_1: 0.8959 - dsc_2: 0.7373\n",
      "Epoch 31/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0933 - dsc_1: 0.8950 - dsc_2: 0.7395WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0933 - dsc_1: 0.8950 - dsc_2: 0.7395\n",
      "Epoch 32/200\n",
      "150/150 [==============================] - 20s 131ms/step - loss: 0.0949 - dsc_1: 0.8969 - dsc_2: 0.7395 - val_loss: 0.0989 - val_dsc_1: 0.8963 - val_dsc_2: 0.7130\n",
      "Epoch 33/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0908 - dsc_1: 0.9016 - dsc_2: 0.7468WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0908 - dsc_1: 0.9016 - dsc_2: 0.7468\n",
      "Epoch 34/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0927 - dsc_1: 0.8974 - dsc_2: 0.7517WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0927 - dsc_1: 0.8974 - dsc_2: 0.7517\n",
      "Epoch 35/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0908 - dsc_1: 0.9020 - dsc_2: 0.7468WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0908 - dsc_1: 0.9020 - dsc_2: 0.7468\n",
      "Epoch 36/200\n",
      "150/150 [==============================] - 20s 130ms/step - loss: 0.0884 - dsc_1: 0.8992 - dsc_2: 0.7533 - val_loss: 0.0997 - val_dsc_1: 0.8879 - val_dsc_2: 0.7080\n",
      "Epoch 37/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0860 - dsc_1: 0.9031 - dsc_2: 0.7558WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0860 - dsc_1: 0.9031 - dsc_2: 0.7558\n",
      "Epoch 38/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0911 - dsc_1: 0.8978 - dsc_2: 0.7413WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0911 - dsc_1: 0.8978 - dsc_2: 0.7413\n",
      "Epoch 39/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0879 - dsc_1: 0.9023 - dsc_2: 0.7526WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0879 - dsc_1: 0.9023 - dsc_2: 0.7526\n",
      "Epoch 40/200\n",
      "150/150 [==============================] - 19s 129ms/step - loss: 0.0860 - dsc_1: 0.9081 - dsc_2: 0.7492 - val_loss: 0.0966 - val_dsc_1: 0.8949 - val_dsc_2: 0.7208\n",
      "Epoch 41/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0874 - dsc_1: 0.9006 - dsc_2: 0.7630WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0874 - dsc_1: 0.9006 - dsc_2: 0.7630\n",
      "Epoch 42/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0843 - dsc_1: 0.9050 - dsc_2: 0.7537WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0843 - dsc_1: 0.9050 - dsc_2: 0.7537\n",
      "Epoch 43/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0845 - dsc_1: 0.9091 - dsc_2: 0.7688WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0845 - dsc_1: 0.9091 - dsc_2: 0.7688\n",
      "Epoch 44/200\n",
      "150/150 [==============================] - 19s 130ms/step - loss: 0.0841 - dsc_1: 0.9058 - dsc_2: 0.7637 - val_loss: 0.0941 - val_dsc_1: 0.8972 - val_dsc_2: 0.7269\n",
      "Epoch 45/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0862 - dsc_1: 0.9016 - dsc_2: 0.7549WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0862 - dsc_1: 0.9016 - dsc_2: 0.7549\n",
      "Epoch 46/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0837 - dsc_1: 0.9095 - dsc_2: 0.7700WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0837 - dsc_1: 0.9095 - dsc_2: 0.7700\n",
      "Epoch 47/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0824 - dsc_1: 0.9045 - dsc_2: 0.7678WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0824 - dsc_1: 0.9045 - dsc_2: 0.7678\n",
      "Epoch 48/200\n",
      "150/150 [==============================] - 19s 128ms/step - loss: 0.0850 - dsc_1: 0.9074 - dsc_2: 0.7599 - val_loss: 0.0921 - val_dsc_1: 0.9007 - val_dsc_2: 0.7182\n",
      "Epoch 49/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0824 - dsc_1: 0.9037 - dsc_2: 0.7516WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0824 - dsc_1: 0.9037 - dsc_2: 0.7516\n",
      "Epoch 50/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0810 - dsc_1: 0.9113 - dsc_2: 0.7709WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0810 - dsc_1: 0.9113 - dsc_2: 0.7709\n",
      "Epoch 51/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0803 - dsc_1: 0.9125 - dsc_2: 0.7686WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0803 - dsc_1: 0.9125 - dsc_2: 0.7686\n",
      "Epoch 52/200\n",
      "150/150 [==============================] - 20s 130ms/step - loss: 0.0805 - dsc_1: 0.9094 - dsc_2: 0.7712 - val_loss: 0.0930 - val_dsc_1: 0.8957 - val_dsc_2: 0.7204\n",
      "Epoch 53/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0810 - dsc_1: 0.9129 - dsc_2: 0.7784WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0810 - dsc_1: 0.9129 - dsc_2: 0.7784\n",
      "Epoch 54/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0784 - dsc_1: 0.9114 - dsc_2: 0.7764WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0784 - dsc_1: 0.9114 - dsc_2: 0.7764\n",
      "Epoch 55/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0783 - dsc_1: 0.9134 - dsc_2: 0.7696WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0783 - dsc_1: 0.9134 - dsc_2: 0.7696\n",
      "Epoch 56/200\n",
      "150/150 [==============================] - 19s 128ms/step - loss: 0.0765 - dsc_1: 0.9120 - dsc_2: 0.7735 - val_loss: 0.0959 - val_dsc_1: 0.8979 - val_dsc_2: 0.7231\n",
      "Epoch 57/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0810 - dsc_1: 0.9126 - dsc_2: 0.7685WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0810 - dsc_1: 0.9126 - dsc_2: 0.7685\n",
      "Epoch 58/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0765 - dsc_1: 0.9130 - dsc_2: 0.7832WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0765 - dsc_1: 0.9130 - dsc_2: 0.7832\n",
      "Epoch 59/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0776 - dsc_1: 0.9118 - dsc_2: 0.7768WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0776 - dsc_1: 0.9118 - dsc_2: 0.7768\n",
      "Epoch 60/200\n",
      "150/150 [==============================] - 19s 129ms/step - loss: 0.0781 - dsc_1: 0.9129 - dsc_2: 0.7716 - val_loss: 0.0924 - val_dsc_1: 0.8986 - val_dsc_2: 0.7314\n",
      "Epoch 61/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0779 - dsc_1: 0.9138 - dsc_2: 0.7776WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0779 - dsc_1: 0.9138 - dsc_2: 0.7776\n",
      "Epoch 62/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0777 - dsc_1: 0.9125 - dsc_2: 0.7770WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 58ms/step - loss: 0.0777 - dsc_1: 0.9125 - dsc_2: 0.7770\n",
      "Epoch 63/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0754 - dsc_1: 0.9148 - dsc_2: 0.7838WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0754 - dsc_1: 0.9148 - dsc_2: 0.7838\n",
      "Epoch 64/200\n",
      "150/150 [==============================] - 20s 131ms/step - loss: 0.0827 - dsc_1: 0.9039 - dsc_2: 0.7722 - val_loss: 0.0943 - val_dsc_1: 0.8964 - val_dsc_2: 0.7102\n",
      "Epoch 65/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0772 - dsc_1: 0.9173 - dsc_2: 0.7792WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0772 - dsc_1: 0.9173 - dsc_2: 0.7792\n",
      "Epoch 66/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0764 - dsc_1: 0.9148 - dsc_2: 0.7848WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0764 - dsc_1: 0.9148 - dsc_2: 0.7848\n",
      "Epoch 67/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0761 - dsc_1: 0.9142 - dsc_2: 0.7757WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0761 - dsc_1: 0.9142 - dsc_2: 0.7757\n",
      "Epoch 68/200\n",
      "150/150 [==============================] - 20s 131ms/step - loss: 0.0744 - dsc_1: 0.9162 - dsc_2: 0.7815 - val_loss: 0.0903 - val_dsc_1: 0.9035 - val_dsc_2: 0.7408\n",
      "Epoch 69/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0767 - dsc_1: 0.9158 - dsc_2: 0.7847WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0767 - dsc_1: 0.9158 - dsc_2: 0.7847\n",
      "Epoch 70/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0718 - dsc_1: 0.9199 - dsc_2: 0.7952WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0718 - dsc_1: 0.9199 - dsc_2: 0.7952\n",
      "Epoch 71/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0742 - dsc_1: 0.9148 - dsc_2: 0.7810WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0742 - dsc_1: 0.9148 - dsc_2: 0.7810\n",
      "Epoch 72/200\n",
      "150/150 [==============================] - 19s 130ms/step - loss: 0.0755 - dsc_1: 0.9136 - dsc_2: 0.7872 - val_loss: 0.0914 - val_dsc_1: 0.9030 - val_dsc_2: 0.7230\n",
      "Epoch 73/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0715 - dsc_1: 0.9194 - dsc_2: 0.7919WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0715 - dsc_1: 0.9194 - dsc_2: 0.7919\n",
      "Epoch 74/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0737 - dsc_1: 0.9187 - dsc_2: 0.7885WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0737 - dsc_1: 0.9187 - dsc_2: 0.7885\n",
      "Epoch 75/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0744 - dsc_1: 0.9178 - dsc_2: 0.7836WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0744 - dsc_1: 0.9178 - dsc_2: 0.7836\n",
      "Epoch 76/200\n",
      "150/150 [==============================] - 20s 131ms/step - loss: 0.0721 - dsc_1: 0.9172 - dsc_2: 0.7832 - val_loss: 0.0916 - val_dsc_1: 0.8989 - val_dsc_2: 0.7312\n",
      "Epoch 77/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0736 - dsc_1: 0.9190 - dsc_2: 0.7931WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0736 - dsc_1: 0.9190 - dsc_2: 0.7931\n",
      "Epoch 78/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0735 - dsc_1: 0.9180 - dsc_2: 0.7895WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 61ms/step - loss: 0.0735 - dsc_1: 0.9180 - dsc_2: 0.7895\n",
      "Epoch 79/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0713 - dsc_1: 0.9176 - dsc_2: 0.7920WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0713 - dsc_1: 0.9176 - dsc_2: 0.7920\n",
      "Epoch 80/200\n",
      "150/150 [==============================] - 19s 129ms/step - loss: 0.0721 - dsc_1: 0.9185 - dsc_2: 0.7951 - val_loss: 0.0934 - val_dsc_1: 0.8986 - val_dsc_2: 0.7251\n",
      "Epoch 81/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0706 - dsc_1: 0.9211 - dsc_2: 0.7922WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0706 - dsc_1: 0.9211 - dsc_2: 0.7922\n",
      "Epoch 82/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0715 - dsc_1: 0.9188 - dsc_2: 0.7937WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0715 - dsc_1: 0.9188 - dsc_2: 0.7937\n",
      "Epoch 83/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0709 - dsc_1: 0.9231 - dsc_2: 0.7940WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0709 - dsc_1: 0.9231 - dsc_2: 0.7940\n",
      "Epoch 84/200\n",
      "150/150 [==============================] - 20s 130ms/step - loss: 0.0728 - dsc_1: 0.9171 - dsc_2: 0.7917 - val_loss: 0.0921 - val_dsc_1: 0.9022 - val_dsc_2: 0.7392\n",
      "Epoch 85/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0673 - dsc_1: 0.9221 - dsc_2: 0.7975WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0673 - dsc_1: 0.9221 - dsc_2: 0.7975\n",
      "Epoch 86/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0712 - dsc_1: 0.9215 - dsc_2: 0.7958WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0712 - dsc_1: 0.9215 - dsc_2: 0.7958\n",
      "Epoch 87/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0725 - dsc_1: 0.9217 - dsc_2: 0.7981WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0725 - dsc_1: 0.9217 - dsc_2: 0.7981\n",
      "Epoch 88/200\n",
      "150/150 [==============================] - 20s 130ms/step - loss: 0.0677 - dsc_1: 0.9200 - dsc_2: 0.7967 - val_loss: 0.0904 - val_dsc_1: 0.9006 - val_dsc_2: 0.7337\n",
      "Epoch 89/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0692 - dsc_1: 0.9213 - dsc_2: 0.8012WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0692 - dsc_1: 0.9213 - dsc_2: 0.8012\n",
      "Epoch 90/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0697 - dsc_1: 0.9240 - dsc_2: 0.7986WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0697 - dsc_1: 0.9240 - dsc_2: 0.7986\n",
      "Epoch 91/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0707 - dsc_1: 0.9191 - dsc_2: 0.7937WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0707 - dsc_1: 0.9191 - dsc_2: 0.7937\n",
      "Epoch 92/200\n",
      "150/150 [==============================] - 19s 129ms/step - loss: 0.0691 - dsc_1: 0.9217 - dsc_2: 0.7942 - val_loss: 0.0916 - val_dsc_1: 0.9023 - val_dsc_2: 0.7303\n",
      "Epoch 93/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0697 - dsc_1: 0.9230 - dsc_2: 0.8051WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0697 - dsc_1: 0.9230 - dsc_2: 0.8051\n",
      "Epoch 94/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0686 - dsc_1: 0.9246 - dsc_2: 0.7972WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0686 - dsc_1: 0.9246 - dsc_2: 0.7972\n",
      "Epoch 95/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0658 - dsc_1: 0.9229 - dsc_2: 0.8073WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0658 - dsc_1: 0.9229 - dsc_2: 0.8073\n",
      "Epoch 96/200\n",
      "150/150 [==============================] - 19s 129ms/step - loss: 0.0669 - dsc_1: 0.9239 - dsc_2: 0.8078 - val_loss: 0.0937 - val_dsc_1: 0.9031 - val_dsc_2: 0.7264\n",
      "Epoch 97/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0673 - dsc_1: 0.9257 - dsc_2: 0.8054WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0673 - dsc_1: 0.9257 - dsc_2: 0.8054\n",
      "Epoch 98/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0673 - dsc_1: 0.9237 - dsc_2: 0.8027WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0673 - dsc_1: 0.9237 - dsc_2: 0.8027\n",
      "Epoch 99/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0680 - dsc_1: 0.9262 - dsc_2: 0.8062WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0680 - dsc_1: 0.9262 - dsc_2: 0.8062\n",
      "Epoch 100/200\n",
      "150/150 [==============================] - 20s 132ms/step - loss: 0.0674 - dsc_1: 0.9239 - dsc_2: 0.8072 - val_loss: 0.0950 - val_dsc_1: 0.9024 - val_dsc_2: 0.7157\n",
      "Epoch 101/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0668 - dsc_1: 0.9219 - dsc_2: 0.7967WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0668 - dsc_1: 0.9219 - dsc_2: 0.7967\n",
      "Epoch 102/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0666 - dsc_1: 0.9248 - dsc_2: 0.8070WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0666 - dsc_1: 0.9248 - dsc_2: 0.8070\n",
      "Epoch 103/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0672 - dsc_1: 0.9269 - dsc_2: 0.8011WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0672 - dsc_1: 0.9269 - dsc_2: 0.8011\n",
      "Epoch 104/200\n",
      "150/150 [==============================] - 20s 130ms/step - loss: 0.0655 - dsc_1: 0.9253 - dsc_2: 0.8104 - val_loss: 0.0929 - val_dsc_1: 0.9009 - val_dsc_2: 0.7301\n",
      "Epoch 105/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0659 - dsc_1: 0.9262 - dsc_2: 0.8041WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0659 - dsc_1: 0.9262 - dsc_2: 0.8041\n",
      "Epoch 106/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0655 - dsc_1: 0.9278 - dsc_2: 0.8137WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 58ms/step - loss: 0.0655 - dsc_1: 0.9278 - dsc_2: 0.8137\n",
      "Epoch 107/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0653 - dsc_1: 0.9226 - dsc_2: 0.8048WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0653 - dsc_1: 0.9226 - dsc_2: 0.8048\n",
      "Epoch 108/200\n",
      "150/150 [==============================] - 19s 129ms/step - loss: 0.0685 - dsc_1: 0.9241 - dsc_2: 0.8060 - val_loss: 0.0955 - val_dsc_1: 0.8998 - val_dsc_2: 0.7246\n",
      "Epoch 109/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0628 - dsc_1: 0.9268 - dsc_2: 0.8120WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.0628 - dsc_1: 0.9268 - dsc_2: 0.8120\n",
      "Epoch 110/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0660 - dsc_1: 0.9279 - dsc_2: 0.8083WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0660 - dsc_1: 0.9279 - dsc_2: 0.8083\n",
      "Epoch 111/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0657 - dsc_1: 0.9227 - dsc_2: 0.8096WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0657 - dsc_1: 0.9227 - dsc_2: 0.8096\n",
      "Epoch 112/200\n",
      "150/150 [==============================] - 19s 130ms/step - loss: 0.0637 - dsc_1: 0.9259 - dsc_2: 0.8095 - val_loss: 0.0942 - val_dsc_1: 0.9020 - val_dsc_2: 0.7299\n",
      "Epoch 113/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0653 - dsc_1: 0.9267 - dsc_2: 0.8135WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 58ms/step - loss: 0.0653 - dsc_1: 0.9267 - dsc_2: 0.8135\n",
      "Epoch 114/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0663 - dsc_1: 0.9265 - dsc_2: 0.8111WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0663 - dsc_1: 0.9265 - dsc_2: 0.8111\n",
      "Epoch 115/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0645 - dsc_1: 0.9271 - dsc_2: 0.8113WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.0645 - dsc_1: 0.9271 - dsc_2: 0.8113\n",
      "Epoch 116/200\n",
      "150/150 [==============================] - 19s 128ms/step - loss: 0.0632 - dsc_1: 0.9283 - dsc_2: 0.8149 - val_loss: 0.0947 - val_dsc_1: 0.8962 - val_dsc_2: 0.7258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb6bbdc2438>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Compile model\n",
    "model2.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
    "    loss = {'zones': losses.SparseCategoricalCrossentropy(from_logits = True)},\n",
    "    metrics = {'zones': custom.dsc(cls=2)},\n",
    "     experimental_run_tf_function=False\n",
    ")\n",
    "\n",
    "client.load_data_in_memory()\n",
    "\n",
    "callback2 = callbacks.EarlyStopping(monitor='val_dsc_2', patience = 12, restore_best_weights=True, mode= 'max')\n",
    "# --- Train the model\n",
    "model2.fit(\n",
    "    x = gen_train,\n",
    "    steps_per_epoch = 150,\n",
    "    epochs = 200,\n",
    "    validation_data = gen_valid,\n",
    "    validation_steps = 500,\n",
    "    validation_freq = 4,\n",
    "    #use_muiltiprocessing = True,\n",
    "    callbacks = callback2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "55LRpLwS9pRL"
   },
   "source": [
    "## 3. Custom architecture (multiple step)\n",
    "\n",
    "Finally, using all customizations described in class, find a top-performing model that yields some incremental benefit over the two baseline models above. A multi-step approach (using the cropped `128 x 128` inputs) will tend to yield improved results. Additional modifications that be used include (but are not limited to):\n",
    "\n",
    "* hybrid 3D/2D network\n",
    "* residual connections\n",
    "* added convolutions between contracting and expanding layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJWOkh-p9pRN"
   },
   "outputs": [],
   "source": [
    "# --- Select shape\n",
    "configs = {'specs': {'xs': {'dat': {'shape': [3, 128, 128, 1]}}}, 'batch': {'size': 12}}\n",
    "\n",
    "# --- Cropped 128 x 128 (multiple step)\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', keyword='seg-crp', configs=configs)\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEeeQFCf9pRQ"
   },
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yp6uQSqhFcYc"
   },
   "outputs": [],
   "source": [
    "xs, ys= next(gen_train)\n",
    "imshow(xs['dat'][0], figsize=(15, 15))\n",
    "imshow(ys['zones'], figsize=(15, 15))\n",
    "print(ys['zones'].shape)\n",
    "print(xs['dat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtAjHxctKGzT"
   },
   "outputs": [],
   "source": [
    "# --- Define kwargs dictionary\n",
    "kwargs_2 = {\n",
    "    'kernel_size': (1, 3, 3)}\n",
    "# --- Define lambda functions\n",
    "conv_3 = lambda x, filters, padding, strides : layers.Conv3D(filters=filters, strides=strides, padding = padding, **kwargs_2)(x)\n",
    "norm_3 = lambda x : layers.BatchNormalization()(x)\n",
    "relu_3 = lambda x : layers.LeakyReLU()(x)\n",
    "\n",
    "conv_3z = lambda x, filters, padding, strides, kernel_size : layers.Conv3D(filters=filters, strides=strides, padding = padding, kernel_size = kernel_size)(x)\n",
    "\n",
    "validconv = lambda x, filters, kernel_size : layers.Conv3D(filters=filters, kernel_size = kernel_size, padding = 'valid')(x)\n",
    "\n",
    "# --- Define stride-1, stride-2 blocks\n",
    "conv1_3 = lambda filters, x: relu_3(norm_3(conv_3(x, filters, padding = 'same', strides=1)))\n",
    "conv2_3 = lambda filters, x: relu_3(norm_3(conv_3(x, filters, padding = 'same', strides=(1, 2, 2))))\n",
    "conv3_3 = lambda filters, x, kernel_size : relu_3(norm_3(conv_3z(x, filters, kernel_size = kernel_size, padding = 'valid', strides=1)))\n",
    "conv4_3 = lambda filters, x, kernel_size : relu_3(norm_3(conv_3z(x, filters, kernel_size = kernel_size, padding = 'valid', strides=1)))\n",
    "\n",
    "\n",
    "validconvl = lambda filters, x, kernel_size : relu_3(norm_3(validconv(x, filters, kernel_size)))\n",
    "\n",
    "# --- Define single transpose\n",
    "tran_3 = lambda x, filters, strides, padding : layers.Conv3DTranspose(filters=filters, strides=strides, padding = padding, **kwargs_2)(x)\n",
    "\n",
    "# --- Define transpose block\n",
    "tran2_3 = lambda filters, x : relu_3(norm_3(tran_3(x, filters, strides=(1, 2, 2), padding = 'same')))\n",
    "tran3_3 = lambda filters, x : relu_3(norm_3(tran_3(x, filters, strides=(1, 4, 4), padding = 'same')))\n",
    "\n",
    "concat = lambda a,b: layers.Concatenate()([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1951,
     "status": "ok",
     "timestamp": 1589316116727,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "AtrdzLmy9pRR",
    "outputId": "fe80abde-ccaa-4a7e-ef91-a185169effd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dat (InputLayer)                [(None, None, 128, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_62 (Conv3D)              (None, None, 128, 12 800         dat[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, 128, 12 320         conv3d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)      (None, None, 128, 12 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_63 (Conv3D)              (None, None, 64, 64, 57680       leaky_re_lu_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, 64, 64, 320         conv3d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_64 (Conv3D)              (None, None, 64, 64, 115360      leaky_re_lu_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, 64, 64, 640         conv3d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_80 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_65 (Conv3D)              (None, None, 32, 32, 230560      leaky_re_lu_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, 32, 32, 640         conv3d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_81 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_66 (Conv3D)              (None, None, 32, 32, 461120      leaky_re_lu_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, 32, 32, 1280        conv3d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_82 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_67 (Conv3D)              (None, None, 16, 16, 921920      leaky_re_lu_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, 16, 16, 1280        conv3d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)      (None, None, 16, 16, 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_68 (Conv3D)              (None, None, 16, 16, 410240      leaky_re_lu_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, 16, 16, 2560        conv3d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_84 (LeakyReLU)      (None, None, 16, 16, 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_69 (Conv3D)              (None, None, 8, 8, 6 3687040     leaky_re_lu_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, 8, 8, 6 2560        conv3d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_85 (LeakyReLU)      (None, None, 8, 8, 6 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_70 (Conv3D)              (None, None, 8, 8, 1 1639680     leaky_re_lu_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, 8, 8, 1 5120        conv3d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_86 (LeakyReLU)      (None, None, 8, 8, 1 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_16 (Conv3DTran (None, None, 16, 16, 7373440     leaky_re_lu_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_71 (Conv3D)              (None, None, 16, 16, 819840      leaky_re_lu_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, 16, 16, 2560        conv3d_transpose_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, 16, 16, 2560        conv3d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_87 (LeakyReLU)      (None, None, 16, 16, 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_88 (LeakyReLU)      (None, None, 16, 16, 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_7 (TensorFlow [(None, None, 16, 16 0           leaky_re_lu_87[0][0]             \n",
      "                                                                 leaky_re_lu_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_72 (Conv3D)              (None, None, 16, 16, 3687040     tf_op_layer_AddV2_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, 16, 16, 2560        conv3d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_89 (LeakyReLU)      (None, None, 16, 16, 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_73 (Conv3D)              (None, None, 16, 16, 3687040     leaky_re_lu_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, 16, 16, 2560        conv3d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_90 (LeakyReLU)      (None, None, 16, 16, 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_17 (Conv3DTran (None, None, 32, 32, 1843520     leaky_re_lu_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_74 (Conv3D)              (None, None, 32, 32, 307520      leaky_re_lu_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, 32, 32, 1280        conv3d_transpose_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, 32, 32, 1280        conv3d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_91 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_92 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_8 (TensorFlow [(None, None, 32, 32 0           leaky_re_lu_91[0][0]             \n",
      "                                                                 leaky_re_lu_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_75 (Conv3D)              (None, None, 32, 32, 921920      tf_op_layer_AddV2_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, 32, 32, 1280        conv3d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_93 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_76 (Conv3D)              (None, None, 32, 32, 921920      leaky_re_lu_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, 32, 32, 1280        conv3d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_94 (LeakyReLU)      (None, None, 32, 32, 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_18 (Conv3DTran (None, None, 64, 64, 460960      leaky_re_lu_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_77 (Conv3D)              (None, None, 64, 64, 76960       leaky_re_lu_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, 64, 64, 640         conv3d_transpose_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, 64, 64, 640         conv3d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_95 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_96 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_9 (TensorFlow [(None, None, 64, 64 0           leaky_re_lu_95[0][0]             \n",
      "                                                                 leaky_re_lu_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_78 (Conv3D)              (None, None, 64, 64, 230560      tf_op_layer_AddV2_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, 64, 64, 640         conv3d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_97 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_79 (Conv3D)              (None, None, 64, 64, 230560      leaky_re_lu_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, 64, 64, 640         conv3d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_98 (LeakyReLU)      (None, None, 64, 64, 0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_19 (Conv3DTran (None, None, 128, 12 115280      leaky_re_lu_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, None, 128, 12 320         conv3d_transpose_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_99 (LeakyReLU)      (None, None, 128, 12 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zones (Conv3D)                  (None, None, 128, 12 2163        leaky_re_lu_99[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 28,236,083\n",
      "Trainable params: 28,219,603\n",
      "Non-trainable params: 16,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# --- Define model\n",
    "\n",
    "a = 10\n",
    "\n",
    "l2_3step = conv1_3(8*a, inputs['dat'])\n",
    "l3_3step = conv1_3(16*a, conv2_3(8*a,l2_3step))\n",
    "l4_3step = conv1_3(32*a, conv2_3(16*a,l3_3step))\n",
    "l5_3step = conv3_3(64*a, conv2_3(32*a,l4_3step), (2,1,1))\n",
    "l6_3step = conv3_3(128*a, conv2_3(64*a,l5_3step), (2,1,1))\n",
    "\n",
    "\n",
    "l7_3step = tran2_3(64*a, l6_3step)\n",
    "l8_3step = tran2_3(32*a, conv1_3(64*a, conv1_3(64*a, l7_3step + conv3_3(64*a, l5_3step, (2,1,1))))) #residual not concat\n",
    "l9_3step = tran2_3(16*a, conv1_3(32*a, conv1_3(32*a, l8_3step + conv3_3(32*a, l4_3step, (3,1,1))))) #residual not concat\n",
    " \n",
    "l10_3step = tran2_3(8*a, conv1_3(16*a, conv1_3(16*a,l9_3step + conv3_3(16*a, l3_3step, (3,1,1)))))\n",
    "\n",
    "\n",
    "\n",
    "# --- Create logits\n",
    "logits_3step = {}\n",
    "logits_3step['zones'] = layers.Conv3D(filters=3, kernel_size = (1,3,3), name='zones', padding = 'same')(l10_3step)\n",
    "\n",
    "\n",
    "# --- Create model\n",
    "model3 = Model(inputs=inputs, outputs=logits_3step)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eo4ZMqv09pRU"
   },
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15780550,
     "status": "ok",
     "timestamp": 1589331896738,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "HO4H7gJy9pRV",
    "outputId": "bd27c046-99ae-40c9-d4db-105b3633f6e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-12 20:41:59 ] [====================] 100.000% : Iterating | 000342    Epoch 1/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7924 - dsc_1: 0.5377 - dsc_2: 0.2051WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.7924 - dsc_1: 0.5377 - dsc_2: 0.2051\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3353 - dsc_1: 0.7870 - dsc_2: 0.4710WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.3353 - dsc_1: 0.7870 - dsc_2: 0.4710\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2478 - dsc_1: 0.8244 - dsc_2: 0.5847WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.2478 - dsc_1: 0.8244 - dsc_2: 0.5847\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 330s 3s/step - loss: 0.1977 - dsc_1: 0.8507 - dsc_2: 0.6310 - val_loss: 0.2536 - val_dsc_1: 0.7441 - val_dsc_2: 0.4472\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1678 - dsc_1: 0.8666 - dsc_2: 0.6573WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.1678 - dsc_1: 0.8666 - dsc_2: 0.6573\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1510 - dsc_1: 0.8728 - dsc_2: 0.6815WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.1510 - dsc_1: 0.8728 - dsc_2: 0.6815\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1345 - dsc_1: 0.8825 - dsc_2: 0.6974WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.1345 - dsc_1: 0.8825 - dsc_2: 0.6974\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 330s 3s/step - loss: 0.1260 - dsc_1: 0.8873 - dsc_2: 0.7105 - val_loss: 0.1296 - val_dsc_1: 0.8846 - val_dsc_2: 0.6903\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1180 - dsc_1: 0.8905 - dsc_2: 0.7266WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.1180 - dsc_1: 0.8905 - dsc_2: 0.7266\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1104 - dsc_1: 0.8956 - dsc_2: 0.7342WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.1104 - dsc_1: 0.8956 - dsc_2: 0.7342\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0999 - dsc_1: 0.9059 - dsc_2: 0.7617WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0999 - dsc_1: 0.9059 - dsc_2: 0.7617\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 331s 3s/step - loss: 0.1106 - dsc_1: 0.8879 - dsc_2: 0.7373 - val_loss: 0.1484 - val_dsc_1: 0.8135 - val_dsc_2: 0.6148\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1022 - dsc_1: 0.8975 - dsc_2: 0.7422WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.1022 - dsc_1: 0.8975 - dsc_2: 0.7422\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0937 - dsc_1: 0.9103 - dsc_2: 0.7643WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0937 - dsc_1: 0.9103 - dsc_2: 0.7643\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0860 - dsc_1: 0.9119 - dsc_2: 0.7766WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0860 - dsc_1: 0.9119 - dsc_2: 0.7766\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 330s 3s/step - loss: 0.0840 - dsc_1: 0.9139 - dsc_2: 0.7825 - val_loss: 0.1045 - val_dsc_1: 0.8919 - val_dsc_2: 0.7081\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0810 - dsc_1: 0.9185 - dsc_2: 0.7845WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0810 - dsc_1: 0.9185 - dsc_2: 0.7845\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0802 - dsc_1: 0.9195 - dsc_2: 0.7950WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0802 - dsc_1: 0.9195 - dsc_2: 0.7950\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0810 - dsc_1: 0.9138 - dsc_2: 0.7763WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0810 - dsc_1: 0.9138 - dsc_2: 0.7763\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 330s 3s/step - loss: 0.0768 - dsc_1: 0.9140 - dsc_2: 0.7975 - val_loss: 0.1009 - val_dsc_1: 0.8967 - val_dsc_2: 0.7003\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0746 - dsc_1: 0.9217 - dsc_2: 0.8043WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0746 - dsc_1: 0.9217 - dsc_2: 0.8043\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0741 - dsc_1: 0.9273 - dsc_2: 0.7941WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0741 - dsc_1: 0.9273 - dsc_2: 0.7941\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0754 - dsc_1: 0.9172 - dsc_2: 0.7981WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0754 - dsc_1: 0.9172 - dsc_2: 0.7981\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 329s 3s/step - loss: 0.0703 - dsc_1: 0.9251 - dsc_2: 0.8050 - val_loss: 0.0936 - val_dsc_1: 0.9024 - val_dsc_2: 0.7128\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0680 - dsc_1: 0.9234 - dsc_2: 0.8179WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0680 - dsc_1: 0.9234 - dsc_2: 0.8179\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0639 - dsc_1: 0.9296 - dsc_2: 0.8268WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0639 - dsc_1: 0.9296 - dsc_2: 0.8268\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0625 - dsc_1: 0.9307 - dsc_2: 0.8304WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0625 - dsc_1: 0.9307 - dsc_2: 0.8304\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 329s 3s/step - loss: 0.0665 - dsc_1: 0.9310 - dsc_2: 0.8217 - val_loss: 0.0936 - val_dsc_1: 0.9044 - val_dsc_2: 0.7365\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0586 - dsc_1: 0.9343 - dsc_2: 0.8293WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0586 - dsc_1: 0.9343 - dsc_2: 0.8293\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0566 - dsc_1: 0.9410 - dsc_2: 0.8488WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0566 - dsc_1: 0.9410 - dsc_2: 0.8488\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0530 - dsc_1: 0.9413 - dsc_2: 0.8532WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0530 - dsc_1: 0.9413 - dsc_2: 0.8532\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 329s 3s/step - loss: 0.0548 - dsc_1: 0.9397 - dsc_2: 0.8519 - val_loss: 0.0991 - val_dsc_1: 0.8978 - val_dsc_2: 0.7351\n",
      "Epoch 33/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0547 - dsc_1: 0.9397 - dsc_2: 0.8456WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0547 - dsc_1: 0.9397 - dsc_2: 0.8456\n",
      "Epoch 34/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0560 - dsc_1: 0.9370 - dsc_2: 0.8484WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0560 - dsc_1: 0.9370 - dsc_2: 0.8484\n",
      "Epoch 35/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0493 - dsc_1: 0.9461 - dsc_2: 0.8650WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0493 - dsc_1: 0.9461 - dsc_2: 0.8650\n",
      "Epoch 36/200\n",
      "100/100 [==============================] - 329s 3s/step - loss: 0.0467 - dsc_1: 0.9465 - dsc_2: 0.8692 - val_loss: 0.1204 - val_dsc_1: 0.8883 - val_dsc_2: 0.6935\n",
      "Epoch 37/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0487 - dsc_1: 0.9457 - dsc_2: 0.8631WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0487 - dsc_1: 0.9457 - dsc_2: 0.8631\n",
      "Epoch 38/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0492 - dsc_1: 0.9444 - dsc_2: 0.8636WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0492 - dsc_1: 0.9444 - dsc_2: 0.8636\n",
      "Epoch 39/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0492 - dsc_1: 0.9455 - dsc_2: 0.8622WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0492 - dsc_1: 0.9455 - dsc_2: 0.8622\n",
      "Epoch 40/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0436 - dsc_1: 0.9521 - dsc_2: 0.8805 - val_loss: 0.0995 - val_dsc_1: 0.9030 - val_dsc_2: 0.7397\n",
      "Epoch 41/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0445 - dsc_1: 0.9525 - dsc_2: 0.8784WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0445 - dsc_1: 0.9525 - dsc_2: 0.8784\n",
      "Epoch 42/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0469 - dsc_1: 0.9438 - dsc_2: 0.8728WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0469 - dsc_1: 0.9438 - dsc_2: 0.8728\n",
      "Epoch 43/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0448 - dsc_1: 0.9494 - dsc_2: 0.8716WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0448 - dsc_1: 0.9494 - dsc_2: 0.8716\n",
      "Epoch 44/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0441 - dsc_1: 0.9534 - dsc_2: 0.8732 - val_loss: 0.1037 - val_dsc_1: 0.9028 - val_dsc_2: 0.7249\n",
      "Epoch 45/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0377 - dsc_1: 0.9563 - dsc_2: 0.8904WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0377 - dsc_1: 0.9563 - dsc_2: 0.8904\n",
      "Epoch 46/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0390 - dsc_1: 0.9562 - dsc_2: 0.8887WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0390 - dsc_1: 0.9562 - dsc_2: 0.8887\n",
      "Epoch 47/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0399 - dsc_1: 0.9572 - dsc_2: 0.8916WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0399 - dsc_1: 0.9572 - dsc_2: 0.8916\n",
      "Epoch 48/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0411 - dsc_1: 0.9535 - dsc_2: 0.8849 - val_loss: 0.0997 - val_dsc_1: 0.9078 - val_dsc_2: 0.7494\n",
      "Epoch 49/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0380 - dsc_1: 0.9563 - dsc_2: 0.8916WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0380 - dsc_1: 0.9563 - dsc_2: 0.8916\n",
      "Epoch 50/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0353 - dsc_1: 0.9599 - dsc_2: 0.9004WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0353 - dsc_1: 0.9599 - dsc_2: 0.9004\n",
      "Epoch 51/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0361 - dsc_1: 0.9597 - dsc_2: 0.9006WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0361 - dsc_1: 0.9597 - dsc_2: 0.9006\n",
      "Epoch 52/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0368 - dsc_1: 0.9602 - dsc_2: 0.8969 - val_loss: 0.1019 - val_dsc_1: 0.9078 - val_dsc_2: 0.7478\n",
      "Epoch 53/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0360 - dsc_1: 0.9575 - dsc_2: 0.8943WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0360 - dsc_1: 0.9575 - dsc_2: 0.8943\n",
      "Epoch 54/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0358 - dsc_1: 0.9589 - dsc_2: 0.8983WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0358 - dsc_1: 0.9589 - dsc_2: 0.8983\n",
      "Epoch 55/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0317 - dsc_1: 0.9632 - dsc_2: 0.9071WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0317 - dsc_1: 0.9632 - dsc_2: 0.9071\n",
      "Epoch 56/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0324 - dsc_1: 0.9631 - dsc_2: 0.9081 - val_loss: 0.1109 - val_dsc_1: 0.9029 - val_dsc_2: 0.7275\n",
      "Epoch 57/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0329 - dsc_1: 0.9634 - dsc_2: 0.9083WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0329 - dsc_1: 0.9634 - dsc_2: 0.9083\n",
      "Epoch 58/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0345 - dsc_1: 0.9600 - dsc_2: 0.8999WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0345 - dsc_1: 0.9600 - dsc_2: 0.8999\n",
      "Epoch 59/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0316 - dsc_1: 0.9641 - dsc_2: 0.9079WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0316 - dsc_1: 0.9641 - dsc_2: 0.9079\n",
      "Epoch 60/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0302 - dsc_1: 0.9654 - dsc_2: 0.9152 - val_loss: 0.1113 - val_dsc_1: 0.8991 - val_dsc_2: 0.7412\n",
      "Epoch 61/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0309 - dsc_1: 0.9649 - dsc_2: 0.9080WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0309 - dsc_1: 0.9649 - dsc_2: 0.9080\n",
      "Epoch 62/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0300 - dsc_1: 0.9660 - dsc_2: 0.9144WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0300 - dsc_1: 0.9660 - dsc_2: 0.9144\n",
      "Epoch 63/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0296 - dsc_1: 0.9667 - dsc_2: 0.9149WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0296 - dsc_1: 0.9667 - dsc_2: 0.9149\n",
      "Epoch 64/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0303 - dsc_1: 0.9649 - dsc_2: 0.9102 - val_loss: 0.1195 - val_dsc_1: 0.9044 - val_dsc_2: 0.7043\n",
      "Epoch 65/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0285 - dsc_1: 0.9669 - dsc_2: 0.9198WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0285 - dsc_1: 0.9669 - dsc_2: 0.9198\n",
      "Epoch 66/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0309 - dsc_1: 0.9627 - dsc_2: 0.9105WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0309 - dsc_1: 0.9627 - dsc_2: 0.9105\n",
      "Epoch 67/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0295 - dsc_1: 0.9657 - dsc_2: 0.9166WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0295 - dsc_1: 0.9657 - dsc_2: 0.9166\n",
      "Epoch 68/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0301 - dsc_1: 0.9667 - dsc_2: 0.9149 - val_loss: 0.1267 - val_dsc_1: 0.8898 - val_dsc_2: 0.7326\n",
      "Epoch 69/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0280 - dsc_1: 0.9676 - dsc_2: 0.9185WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0280 - dsc_1: 0.9676 - dsc_2: 0.9185\n",
      "Epoch 70/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0273 - dsc_1: 0.9692 - dsc_2: 0.9178WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0273 - dsc_1: 0.9692 - dsc_2: 0.9178\n",
      "Epoch 71/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0268 - dsc_1: 0.9685 - dsc_2: 0.9236WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0268 - dsc_1: 0.9685 - dsc_2: 0.9236\n",
      "Epoch 72/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0280 - dsc_1: 0.9670 - dsc_2: 0.9199 - val_loss: 0.1186 - val_dsc_1: 0.9019 - val_dsc_2: 0.7351\n",
      "Epoch 73/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0277 - dsc_1: 0.9681 - dsc_2: 0.9210WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0277 - dsc_1: 0.9681 - dsc_2: 0.9210\n",
      "Epoch 74/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0254 - dsc_1: 0.9690 - dsc_2: 0.9247WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0254 - dsc_1: 0.9690 - dsc_2: 0.9247\n",
      "Epoch 75/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0260 - dsc_1: 0.9706 - dsc_2: 0.9271WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0260 - dsc_1: 0.9706 - dsc_2: 0.9271\n",
      "Epoch 76/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0264 - dsc_1: 0.9702 - dsc_2: 0.9250 - val_loss: 0.1144 - val_dsc_1: 0.9089 - val_dsc_2: 0.7387\n",
      "Epoch 77/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0259 - dsc_1: 0.9685 - dsc_2: 0.9231WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0259 - dsc_1: 0.9685 - dsc_2: 0.9231\n",
      "Epoch 78/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0259 - dsc_1: 0.9715 - dsc_2: 0.9245WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0259 - dsc_1: 0.9715 - dsc_2: 0.9245\n",
      "Epoch 79/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0248 - dsc_1: 0.9711 - dsc_2: 0.9288WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0248 - dsc_1: 0.9711 - dsc_2: 0.9288\n",
      "Epoch 80/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0280 - dsc_1: 0.9676 - dsc_2: 0.9211 - val_loss: 0.1142 - val_dsc_1: 0.8991 - val_dsc_2: 0.7448\n",
      "Epoch 81/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0241 - dsc_1: 0.9728 - dsc_2: 0.9298WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0241 - dsc_1: 0.9728 - dsc_2: 0.9298\n",
      "Epoch 82/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0233 - dsc_1: 0.9735 - dsc_2: 0.9326WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0233 - dsc_1: 0.9735 - dsc_2: 0.9326\n",
      "Epoch 83/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0257 - dsc_1: 0.9701 - dsc_2: 0.9255WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0257 - dsc_1: 0.9701 - dsc_2: 0.9255\n",
      "Epoch 84/200\n",
      "100/100 [==============================] - 332s 3s/step - loss: 0.0241 - dsc_1: 0.9717 - dsc_2: 0.9272 - val_loss: 0.1204 - val_dsc_1: 0.9052 - val_dsc_2: 0.7493\n",
      "Epoch 85/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0232 - dsc_1: 0.9728 - dsc_2: 0.9320WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0232 - dsc_1: 0.9728 - dsc_2: 0.9320\n",
      "Epoch 86/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0234 - dsc_1: 0.9727 - dsc_2: 0.9329WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0234 - dsc_1: 0.9727 - dsc_2: 0.9329\n",
      "Epoch 87/200\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0236 - dsc_1: 0.9723 - dsc_2: 0.9305WARNING:tensorflow:Early stopping conditioned on metric `val_dsc_2` which is not available. Available metrics are: loss,dsc_1,dsc_2\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0236 - dsc_1: 0.9723 - dsc_2: 0.9305\n",
      "Epoch 88/200\n",
      "100/100 [==============================] - 333s 3s/step - loss: 0.0247 - dsc_1: 0.9724 - dsc_2: 0.9310 - val_loss: 0.1224 - val_dsc_1: 0.9084 - val_dsc_2: 0.7444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb6a388b0b8>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-5),\n",
    "    loss = {'zones': losses.SparseCategoricalCrossentropy(from_logits = True)},\n",
    "    metrics = {'zones': custom.dsc(cls=2)},\n",
    "     experimental_run_tf_function=False\n",
    ")\n",
    "\n",
    "client.load_data_in_memory()\n",
    "\n",
    "callback3 = callbacks.EarlyStopping(monitor='val_dsc_2', patience = 10, restore_best_weights=True, mode= 'max')\n",
    "# --- Train the model\n",
    "model3.fit(\n",
    "    x = gen_train,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 200,\n",
    "    validation_data = gen_valid,\n",
    "    validation_steps = 500,\n",
    "    validation_freq = 4,\n",
    "#    use_muiltiprocessing = True,\n",
    "    callbacks = callback3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3A6vAJzF9pRY"
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "For each of the three models, the following metrics should be calculated for **both the training and validation** cohorts:\n",
    "\n",
    "* Dice score, mean\n",
    "* Dice score, median\n",
    "* Dice score, 25th percentile\n",
    "* Dice score, 75th percentile\n",
    "\n",
    "The Dice score values should be calculated both for peripheral and transitional zone (class 1 and 2); the Dice score for background does not need to be evaluated. As in prior assignments, accuracy is determined on a patient by patient (volume by volume) basis, so please calculate the Dice score values on the entire 3D volume (not slice-by-slice).\n",
    "\n",
    "### Performance\n",
    "\n",
    "The following minimum performance metrics must be met for full credit:\n",
    "\n",
    "1. 2D U-Net, single step (full 256 x 256)\n",
    "\n",
    "* peripheral zone: mean Dice score > 0.75\n",
    "* transitional zone: mean Dice score > 0.55\n",
    "\n",
    "2. 2D U-Net, multiple step (cropped)\n",
    "\n",
    "* peripheral zone: mean Dice score > 0.80\n",
    "* transitional zone: mean Dice score > 0.60\n",
    "\n",
    "3. Custom architecture\n",
    "\n",
    "* peripeheral zone: mean Dice score > 0.85\n",
    "* transitional zone: mean Dice score > 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4PwzGt4CGWg"
   },
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred, c=1, epsilon=1):\n",
    "    \"\"\"\n",
    "    Method to calculate the Dice score coefficient for given class\n",
    "    \n",
    "    :params\n",
    "    \n",
    "      (np.ndarray) y_true : ground-truth label\n",
    "      (np.ndarray) y_pred : predicted logits scores\n",
    "      (int)             c : class to calculate DSC on\n",
    "    \n",
    "    \"\"\"\n",
    "    assert y_true.ndim == y_pred.ndim\n",
    "    \n",
    "    true = y_true[..., 0] == c\n",
    "    pred = np.argmax(y_pred, axis=-1) == c \n",
    "\n",
    "    A = np.count_nonzero(true & pred) * 2\n",
    "    B = np.count_nonzero(true) + np.count_nonzero(pred) + epsilon\n",
    "    \n",
    "    return A / B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15878404,
     "status": "ok",
     "timestamp": 1589331996673,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "-SsNJMHWCRnp",
    "outputId": "aa943e1a-0928-47fd-dc33-21e008d5b407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-13 01:05:23 ] [=>..................] 7.246% : Iterating | 000005      WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb6a0ef6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 01:05:26 ] [=>..................] 8.696% : Iterating | 000006      WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb6a0ef6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 01:05:29 ] [==>.................] 10.145% : Iterating | 000007     WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb6a0ef6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 01:05:33 ] [==>.................] 13.043% : Iterating | 000009     WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb6a0ef6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 01:05:37 ] [==>.................] 14.493% : Iterating | 000010     WARNING:tensorflow:9 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb6a0ef6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 01:05:42 ] [====>...............] 20.290% : Iterating | 000014     WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb6a0ef6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 01:06:34 ] [====================] 100.000% : Iterating | 000069    \n",
      "\n",
      "\n",
      "0.8916592099269555\n",
      "0.7098268406971001\n",
      "0.8956953994381515\n",
      "0.7272354514945798\n",
      "0.8989691195042646\n",
      "0.7374060235649634\n",
      "\n",
      "\n",
      "\n",
      "0.8972178712612814\n",
      "0.7236228224115053\n",
      "0.9099822046133701\n",
      "0.7634151077739659\n",
      "0.9117722100321478\n",
      "0.7655250480427515\n",
      "\n",
      "\n",
      "\n",
      "0.870607705814681\n",
      "0.6532479414455626\n",
      "0.8810280750458962\n",
      "0.6629756862221926\n",
      "0.8764164527640393\n",
      "0.6878248440748441\n",
      "\n",
      "\n",
      "\n",
      "0.9187661007992602\n",
      "0.7772131068196119\n",
      "0.9197492509285724\n",
      "0.800596470880623\n",
      "0.9273827998955149\n",
      "0.8109188814544291\n"
     ]
    }
   ],
   "source": [
    "dsc_pz_1 = []\n",
    "dsc_tz_1 = []\n",
    "\n",
    "dsc_pz_2 = []\n",
    "dsc_tz_2 = []\n",
    "\n",
    "dsc_pz_3 = []\n",
    "dsc_tz_3 = []\n",
    "\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', keyword='seg-256')\n",
    "inputs = client.get_inputs(Input)\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
    "\n",
    "for x, y in test_valid:\n",
    "    \n",
    "#    print(x['dat'].shape)\n",
    "#    print(y['zones'].shape)\n",
    "#    imshow(xs['dat'][0], figsize=(12, 12))\n",
    "#    imshow(ys['zones'], figsize=(12, 12))\n",
    "    # --- Predict)\n",
    "    logits_1 = model.predict(x['dat'])\n",
    "    if type(logits_1) is dict:\n",
    "        logits_1 = logits_1['zones'] \n",
    "\n",
    "    # --- Argmax\n",
    "    dsc_pz_1.append(dice(y['zones'][0], logits_1[0], c=1))\n",
    "    dsc_tz_1.append(dice(y['zones'][0], logits_1[0], c=2))\n",
    "\n",
    "# --- Select shape\n",
    "configs = {'specs': {'xs': {'dat': {'shape': [3, 128, 128, 1]}}}, 'batch': {'size': 12}}\n",
    "\n",
    "# --- Cropped 128 x 128 (multiple step)\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', keyword='seg-crp', configs=configs)\n",
    "inputs = client.get_inputs(Input)\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
    "\n",
    "for x, y in test_valid:\n",
    "    \n",
    "#    print(x['dat'].shape)\n",
    "#    print(y['zones'].shape)\n",
    "#    imshow(xs['dat'][0], figsize=(12, 12))\n",
    "#    imshow(ys['zones'], figsize=(12, 12))\n",
    "    # --- Predict\n",
    "    x['dat_3'] = np.pad(x['dat'], ((0, 0), (1, 1), (0, 0), (0, 0), (0, 0)))\n",
    "    logits_2 = model2.predict(x['dat'])\n",
    "    if type(logits_1) is dict:\n",
    "        logits_1 = logits_1['zones']\n",
    "    if type(logits_2) is dict:\n",
    "        logits_2 = logits_2['zones']     \n",
    "\n",
    "    # --- Argmax\n",
    "    dsc_pz_2.append(dice(y['zones'][0], logits_2[0], c=1))\n",
    "    dsc_tz_2.append(dice(y['zones'][0], logits_2[0], c=2))\n",
    "\n",
    "\n",
    "    logits_3 = model3.predict(x['dat_3'])\n",
    "\n",
    "    if type(logits_3) is dict:\n",
    "        logits_3 = logits_3['zones']    \n",
    "\n",
    "    dsc_pz_3.append(dice(y['zones'][0], logits_3[0], c=1))\n",
    "    dsc_tz_3.append(dice(y['zones'][0], logits_3[0], c=2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dsc_pz_1 = np.array(dsc_pz_1)\n",
    "dsc_tz_1 = np.array(dsc_tz_1)\n",
    "\n",
    "dsc_pz_2 = np.array(dsc_pz_2)\n",
    "dsc_tz_2 = np.array(dsc_tz_2)\n",
    "\n",
    "dsc_pz_3 = np.array(dsc_pz_3)\n",
    "dsc_tz_3 = np.array(dsc_tz_3)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(index=np.arange(dsc_tz_3.size))\n",
    "\n",
    "\n",
    "df['dsc_pz_1'] = dsc_pz_1\n",
    "df['dsc_tz_1'] = dsc_tz_1\n",
    "\n",
    "df['dsc_pz_2'] = dsc_pz_2\n",
    "df['dsc_tz_2'] = dsc_tz_2\n",
    "\n",
    "df['dsc_pz_3'] = dsc_pz_3\n",
    "df['dsc_tz_3'] = dsc_tz_3\n",
    "\n",
    "df['dsc_pz_1.mean'] = df['dsc_pz_1'].mean()\n",
    "df['dsc_tz_1.mean'] = df['dsc_tz_1'].mean()\n",
    "\n",
    "df['dsc_pz_2.mean'] = df['dsc_pz_2'].mean()\n",
    "df['dsc_tz_2.mean'] = df['dsc_tz_2'].mean()\n",
    "\n",
    "df['dsc_pz_3.mean'] = df['dsc_pz_3'].mean()\n",
    "df['dsc_tz_3.mean'] = df['dsc_tz_3'].mean()\n",
    "\n",
    "\n",
    "df['dsc_pz_1.median'] = df['dsc_pz_1'].median()\n",
    "df['dsc_tz_1.median'] = df['dsc_tz_1'].median()\n",
    "\n",
    "df['dsc_pz_2.median'] = df['dsc_pz_2'].median()\n",
    "df['dsc_tz_2.median'] = df['dsc_tz_2'].median()\n",
    "\n",
    "df['dsc_pz_3.median'] = df['dsc_pz_3'].median()\n",
    "df['dsc_tz_3.median'] = df['dsc_tz_3'].median()\n",
    "\n",
    "df['dsc_pz_1.quantile_25'] = df['dsc_pz_1'].quantile(0.25)\n",
    "df['dsc_tz_1.quantile_25'] = df['dsc_tz_1'].quantile(0.25)\n",
    "\n",
    "df['dsc_pz_2.quantile_25'] = df['dsc_pz_2'].quantile(0.25)\n",
    "df['dsc_tz_2.quantile_25'] = df['dsc_tz_2'].quantile(0.25)\n",
    "\n",
    "df['dsc_pz_3.quantile_25'] = df['dsc_pz_3'].quantile(0.25)\n",
    "df['dsc_tz_3.quantile_25'] = df['dsc_tz_3'].quantile(0.25)\n",
    "\n",
    "df['dsc_pz_1.quantile_75'] = df['dsc_pz_1'].quantile(0.75)\n",
    "df['dsc_tz_1.quantile_75'] = df['dsc_tz_1'].quantile(0.75)\n",
    "\n",
    "df['dsc_pz_2.quantile_75'] = df['dsc_pz_2'].quantile(0.75)\n",
    "df['dsc_tz_2.quantile_75'] = df['dsc_tz_2'].quantile(0.75)\n",
    "\n",
    "df['dsc_pz_3.quantile_75'] = df['dsc_pz_3'].quantile(0.75)\n",
    "df['dsc_tz_3.quantile_75'] = df['dsc_tz_3'].quantile(0.75)\n",
    "\n",
    "\n",
    "\n",
    "# --- Print accuracy\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print(df['dsc_pz_1'].mean())\n",
    "print(df['dsc_tz_1'].mean())\n",
    "\n",
    "print(df['dsc_pz_2'].mean())\n",
    "print(df['dsc_tz_2'].mean())\n",
    "\n",
    "print(df['dsc_pz_3'].mean())\n",
    "print(df['dsc_tz_3'].mean())\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "\n",
    "print(df['dsc_pz_1'].median())\n",
    "print(df['dsc_tz_1'].median())\n",
    "\n",
    "print(df['dsc_pz_2'].median())\n",
    "print(df['dsc_tz_2'].median())\n",
    "\n",
    "print(df['dsc_pz_3'].median())\n",
    "print(df['dsc_tz_3'].median())\n",
    "\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "\n",
    "print(df['dsc_pz_1'].quantile(0.25))\n",
    "print(df['dsc_tz_1'].quantile(0.25))\n",
    "\n",
    "print(df['dsc_pz_2'].quantile(0.25))\n",
    "print(df['dsc_tz_2'].quantile(0.25))\n",
    "\n",
    "print(df['dsc_pz_3'].quantile(0.25))\n",
    "print(df['dsc_tz_3'].quantile(0.25))\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "\n",
    "print(df['dsc_pz_1'].quantile(0.75))\n",
    "print(df['dsc_tz_1'].quantile(0.75))\n",
    "\n",
    "print(df['dsc_pz_2'].quantile(0.75))\n",
    "print(df['dsc_tz_2'].quantile(0.75))\n",
    "\n",
    "print(df['dsc_pz_3'].quantile(0.75))\n",
    "print(df['dsc_tz_3'].quantile(0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mYD-KuWC9pRc"
   },
   "source": [
    "### Results\n",
    "\n",
    "When ready, create a `*.csv` file with your compiled **training and validation** cohort statistics for the three different models. Consider the following table format (although any format that contains the required information is sufficient):\n",
    "\n",
    "```\n",
    "          TRANSITIONAL ZONE                       PERIPHERAL ZONE\n",
    "          mean | median | 25th-tile | 75th-tile | mean | median | 25th-tile | 75th-tile\n",
    "model 1\n",
    "model 2\n",
    "model 3\n",
    "```\n",
    "\n",
    "As above, tables for both training and validation should be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgFMrYwZ9pRc"
   },
   "outputs": [],
   "source": [
    "# --- Create *.csv\n",
    "                              \n",
    "# --- Serialize *.csv\n",
    "fname = '{}/models/midterm/model.hdf5'.format(MOUNT_ROOT)\n",
    "fname2 = '{}/models/midterm/model2.hdf5'.format(MOUNT_ROOT)\n",
    "fname3 = '{}/models/midterm/model3.hdf5'.format(MOUNT_ROOT)\n",
    "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "df.to_csv('midterm.csv')\n",
    "model.save(fname)\n",
    "model2.save(fname2)\n",
    "model3.save(fname3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Midterm.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/peterchang77/dl_tutor/blob/master/cs190/notebooks/midterm/assignment.ipynb",
     "timestamp": 1588197768013
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
