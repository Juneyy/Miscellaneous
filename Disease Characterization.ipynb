{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2SaViObvF3z2"
   },
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYp09pdUF3z3"
   },
   "source": [
    "### Mount Google Drive\n",
    "\n",
    "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1590695244982,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "dNsKkg0lF3z5",
    "outputId": "c5c0a368-11c2-4c02-8748-be8a97b9ae68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # --- Mount gdrive to /content/drive/My Drive/\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T80CXXshF30A"
   },
   "source": [
    "Throughout this assignment we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RYcU73iIF30A"
   },
   "outputs": [],
   "source": [
    "# --- Set data directory\n",
    "MOUNT_ROOT = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SRejeuJPF30G"
   },
   "source": [
    "### Select Tensorflow library version\n",
    "\n",
    "This assignment will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4076,
     "status": "ok",
     "timestamp": 1590695248218,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "fzmNaUEKF30H",
    "outputId": "e5139b94-7dcd-4036-fead-587bd83d9e91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.1 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.29.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (2.1.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (3.2.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.34.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.18.4)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (3.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (2.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.0.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.7.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (46.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.2.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1) (2.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (2.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.3.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (4.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# --- Select Tensorflow 2.0 (only in Google Colab)\n",
    "% tensorflow_version 2.x\n",
    "% pip install tensorflow-gpu==2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GeDRnO9CF30L"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnbs11aWF30M"
   },
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7058,
     "status": "ok",
     "timestamp": 1590695251205,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "YLaFaE3yF30M",
    "outputId": "2a037a73-de4d-40da-962f-4f3677cd5af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jarvis-md in /usr/local/lib/python3.6/dist-packages (0.0.1a10)\n",
      "Requirement already satisfied: pyyaml>=5.2 in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (5.3.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.0.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.23.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.18.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (3.2.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2018.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->jarvis-md) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Z7X-Fh4F30R"
   },
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuCY2WWlF30S"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers, metrics, callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from jarvis.train import datasets, custom\n",
    "from jarvis.train.client import Client\n",
    "from jarvis.utils.general import overload, tools as jtools\n",
    "from jarvis.utils.display import imshow\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYenOY8oF30W"
   },
   "source": [
    "# Data\n",
    "\n",
    "The data used in this tutorial will consist of (frontal projection) chest radiographs from the RSNA / Kaggle pneumonia challenge (https://www.kaggle.com/c/rsna-pneumonia-detection-challenge). The chest radiograph is the standard screening exam of choice to identify and trend changes in lung disease including infection (pneumonia). To simulate the problem of small dataset size, only 100 exams will be used for training (50 normal, 50 positive). A separate 100 exams will be used for independent testing.\n",
    "\n",
    "The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/xr_pna`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8279,
     "status": "ok",
     "timestamp": 1590695252436,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "ThX6Oky4F30X",
    "outputId": "cb9da7b7-773e-4d32-c4e2-15b89bd574f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': '/data/raw/xr_pna', 'data': '/data/raw/xr_pna'}"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='xr/pna-mul')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfeUvfKXF30a"
   },
   "source": [
    "# Training\n",
    "\n",
    "To account for the small training cohort size, three separate strategies must be employed:\n",
    "\n",
    "1. A **dual loss function** network with both classification and segmentation losses (as demonstrated in the tutorial)\n",
    "\n",
    "2. A reduced final feature map of either (`8 x 8`) or (`4 x 4`) instead of the (`16 x 16`) used in the demonstration\n",
    "\n",
    "3. At least one of the following (or both) regularizer techniques:\n",
    "\n",
    "* dropout\n",
    "* L2 regularization\n",
    "\n",
    "Feel free to further optimize the network architecture to further improve model performance. Recommendings include limiting model size to reduce overfitting, early stopping and mixed L1/L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QbOqUpmVF30b"
   },
   "source": [
    "### Overload the `Client` object\n",
    "\n",
    "*Hint*: Ensure to customize the `arrays['xs']['msk']` object to reflect masked values as shown in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXfYpC0mF30c"
   },
   "outputs": [],
   "source": [
    "@overload(Client)\n",
    "\n",
    "def preprocess(self, arrays,**kwargs):\n",
    "\n",
    "  msk = np.zeros(arrays['xs']['dat'].shape)\n",
    "\n",
    "  lng = arrays['xs']['msk']\n",
    "  pna = arrays['ys']['pna-seg']\n",
    "\n",
    "  msk[lng > 0] = 1\n",
    "  msk[pna > 0] = 3\n",
    "\n",
    "  arrays['xs']['msk'] = msk\n",
    "\n",
    "  return arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RPFCK3RF30f"
   },
   "source": [
    "### Create `Client` object\n",
    "\n",
    "After manually overloading the `Client` object, manually create a new client object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTguMcuuF30h"
   },
   "outputs": [],
   "source": [
    "# --- Find client yml file\n",
    "yml = '{}/data/ymls/client-mul.yml'.format(jtools.get_paths('xr/pna')['code'])\n",
    "\n",
    "# --- Manually create Client\n",
    "client = Client(yml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-7R0Wa5F30l"
   },
   "source": [
    "### Create inputs and generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihMoZHVJF30l"
   },
   "outputs": [],
   "source": [
    "# --- Manually create generators\n",
    "gen_train, gen_valid = client.create_generators()\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qly9AovTF30o"
   },
   "source": [
    "### Define the model\n",
    "\n",
    "*Hint*: Ensure to use both a classification and segmentation (contracting-encoding) architecture as demonstrated in the tutorial. At this point, also ensure to use either dropout or L2 regularization; other regularization techniques may also be explored to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "682hYt3XF30q"
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'kernel_size': (1,3,3),\n",
    "    'padding': 'same'}\n",
    "\n",
    "\n",
    "conv = lambda x, filters, strides, kernel_regularizer : layers.Conv3D(filters = filters, strides = strides, kernel_regularizer = kernel_regularizer, **kwargs)(x)\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "leakyrelu = lambda x: layers.LeakyReLU()(x)\n",
    "transpose = lambda x, filters, strides, kernel_regularizer : layers.Conv3DTranspose(filters = filters, strides = strides, kernel_regularizer = kernel_regularizer, **kwargs)(x)\n",
    "\n",
    "\n",
    "conv1 = lambda filters, x, : leakyrelu(norm(conv(x, filters = filters, strides = (1,1,1), kernel_regularizer = None)))\n",
    "conv2 = lambda filters, x, : leakyrelu(norm(conv(x, filters = filters, strides = (1,2,2), kernel_regularizer = None)))\n",
    "tran = lambda filters, x : leakyrelu(norm(transpose(x, filters, strides = (1,2,2), kernel_regularizer = None)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2560,
     "status": "ok",
     "timestamp": 1590700794088,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "aMtDFoy28953",
    "outputId": "70b34026-b4a1-4ed0-debc-f6fc1b705730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dat (InputLayer)                [(None, 1, 512, 512, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_446 (Conv3D)             (None, 1, 512, 512,  80          dat[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_586 (BatchN (None, 1, 512, 512,  32          conv3d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_586 (LeakyReLU)     (None, 1, 512, 512,  0           batch_normalization_586[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_447 (Conv3D)             (None, 1, 256, 256,  1168        leaky_re_lu_586[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_587 (BatchN (None, 1, 256, 256,  64          conv3d_447[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_587 (LeakyReLU)     (None, 1, 256, 256,  0           batch_normalization_587[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_448 (Conv3D)             (None, 1, 256, 256,  2320        leaky_re_lu_587[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_588 (BatchN (None, 1, 256, 256,  64          conv3d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_588 (LeakyReLU)     (None, 1, 256, 256,  0           batch_normalization_588[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_449 (Conv3D)             (None, 1, 128, 128,  4640        leaky_re_lu_588[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_589 (BatchN (None, 1, 128, 128,  128         conv3d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_589 (LeakyReLU)     (None, 1, 128, 128,  0           batch_normalization_589[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_450 (Conv3D)             (None, 1, 128, 128,  9248        leaky_re_lu_589[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_590 (BatchN (None, 1, 128, 128,  128         conv3d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_590 (LeakyReLU)     (None, 1, 128, 128,  0           batch_normalization_590[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_223 (Dropout)           (None, 1, 128, 128,  0           leaky_re_lu_590[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_451 (Conv3D)             (None, 1, 64, 64, 48 13872       dropout_223[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_591 (BatchN (None, 1, 64, 64, 48 192         conv3d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_591 (LeakyReLU)     (None, 1, 64, 64, 48 0           batch_normalization_591[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_452 (Conv3D)             (None, 1, 64, 64, 48 20784       leaky_re_lu_591[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_592 (BatchN (None, 1, 64, 64, 48 192         conv3d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_592 (LeakyReLU)     (None, 1, 64, 64, 48 0           batch_normalization_592[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_224 (Dropout)           (None, 1, 64, 64, 48 0           leaky_re_lu_592[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_453 (Conv3D)             (None, 1, 32, 32, 64 27712       dropout_224[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_593 (BatchN (None, 1, 32, 32, 64 256         conv3d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_593 (LeakyReLU)     (None, 1, 32, 32, 64 0           batch_normalization_593[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_454 (Conv3D)             (None, 1, 32, 32, 64 36928       leaky_re_lu_593[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_594 (BatchN (None, 1, 32, 32, 64 256         conv3d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_594 (LeakyReLU)     (None, 1, 32, 32, 64 0           batch_normalization_594[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_225 (Dropout)           (None, 1, 32, 32, 64 0           leaky_re_lu_594[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_455 (Conv3D)             (None, 1, 16, 16, 96 55392       dropout_225[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_595 (BatchN (None, 1, 16, 16, 96 384         conv3d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_595 (LeakyReLU)     (None, 1, 16, 16, 96 0           batch_normalization_595[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_456 (Conv3D)             (None, 1, 16, 16, 96 83040       leaky_re_lu_595[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_596 (BatchN (None, 1, 16, 16, 96 384         conv3d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_596 (LeakyReLU)     (None, 1, 16, 16, 96 0           batch_normalization_596[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_226 (Dropout)           (None, 1, 16, 16, 96 0           leaky_re_lu_596[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_457 (Conv3D)             (None, 1, 8, 8, 96)  83040       dropout_226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_597 (BatchN (None, 1, 8, 8, 96)  384         conv3d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_597 (LeakyReLU)     (None, 1, 8, 8, 96)  0           batch_normalization_597[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_458 (Conv3D)             (None, 1, 8, 8, 96)  83040       leaky_re_lu_597[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_598 (BatchN (None, 1, 8, 8, 96)  384         conv3d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_598 (LeakyReLU)     (None, 1, 8, 8, 96)  0           batch_normalization_598[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_227 (Dropout)           (None, 1, 8, 8, 96)  0           leaky_re_lu_598[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_459 (Conv3D)             (None, 1, 4, 4, 96)  83040       dropout_227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_599 (BatchN (None, 1, 4, 4, 96)  384         conv3d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_599 (LeakyReLU)     (None, 1, 4, 4, 96)  0           batch_normalization_599[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_460 (Conv3D)             (None, 1, 4, 4, 96)  83040       leaky_re_lu_599[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_600 (BatchN (None, 1, 4, 4, 96)  384         conv3d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_600 (LeakyReLU)     (None, 1, 4, 4, 96)  0           batch_normalization_600[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_228 (Dropout)           (None, 1, 4, 4, 96)  0           leaky_re_lu_600[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_140 (Conv3DTra (None, 1, 8, 8, 96)  83040       dropout_228[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_603 (BatchN (None, 1, 8, 8, 96)  384         conv3d_transpose_140[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_603 (LeakyReLU)     (None, 1, 8, 8, 96)  0           batch_normalization_603[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_230 (Dropout)           (None, 1, 8, 8, 96)  0           leaky_re_lu_603[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_140 (TensorFlow [(None, 1, 8, 8, 96) 0           dropout_230[0][0]                \n",
      "                                                                 dropout_227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_463 (Conv3D)             (None, 1, 8, 8, 96)  83040       tf_op_layer_add_140[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_604 (BatchN (None, 1, 8, 8, 96)  384         conv3d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_604 (LeakyReLU)     (None, 1, 8, 8, 96)  0           batch_normalization_604[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_141 (Conv3DTra (None, 1, 16, 16, 96 83040       leaky_re_lu_604[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_605 (BatchN (None, 1, 16, 16, 96 384         conv3d_transpose_141[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_605 (LeakyReLU)     (None, 1, 16, 16, 96 0           batch_normalization_605[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_231 (Dropout)           (None, 1, 16, 16, 96 0           leaky_re_lu_605[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_141 (TensorFlow [(None, 1, 16, 16, 9 0           dropout_231[0][0]                \n",
      "                                                                 dropout_226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_464 (Conv3D)             (None, 1, 16, 16, 96 83040       tf_op_layer_add_141[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_606 (BatchN (None, 1, 16, 16, 96 384         conv3d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_606 (LeakyReLU)     (None, 1, 16, 16, 96 0           batch_normalization_606[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_142 (Conv3DTra (None, 1, 32, 32, 64 55360       leaky_re_lu_606[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_607 (BatchN (None, 1, 32, 32, 64 256         conv3d_transpose_142[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_607 (LeakyReLU)     (None, 1, 32, 32, 64 0           batch_normalization_607[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_232 (Dropout)           (None, 1, 32, 32, 64 0           leaky_re_lu_607[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_142 (TensorFlow [(None, 1, 32, 32, 6 0           dropout_232[0][0]                \n",
      "                                                                 dropout_225[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_465 (Conv3D)             (None, 1, 32, 32, 64 36928       tf_op_layer_add_142[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_608 (BatchN (None, 1, 32, 32, 64 256         conv3d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_608 (LeakyReLU)     (None, 1, 32, 32, 64 0           batch_normalization_608[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_143 (Conv3DTra (None, 1, 64, 64, 48 27696       leaky_re_lu_608[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchN (None, 1, 64, 64, 48 192         conv3d_transpose_143[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_609 (LeakyReLU)     (None, 1, 64, 64, 48 0           batch_normalization_609[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_233 (Dropout)           (None, 1, 64, 64, 48 0           leaky_re_lu_609[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_143 (TensorFlow [(None, 1, 64, 64, 4 0           dropout_233[0][0]                \n",
      "                                                                 dropout_224[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_466 (Conv3D)             (None, 1, 64, 64, 48 20784       tf_op_layer_add_143[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchN (None, 1, 64, 64, 48 192         conv3d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_610 (LeakyReLU)     (None, 1, 64, 64, 48 0           batch_normalization_610[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_144 (Conv3DTra (None, 1, 128, 128,  13856       leaky_re_lu_610[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchN (None, 1, 128, 128,  128         conv3d_transpose_144[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_611 (LeakyReLU)     (None, 1, 128, 128,  0           batch_normalization_611[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_234 (Dropout)           (None, 1, 128, 128,  0           leaky_re_lu_611[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_144 (TensorFlow [(None, 1, 128, 128, 0           dropout_234[0][0]                \n",
      "                                                                 dropout_223[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_467 (Conv3D)             (None, 1, 128, 128,  9248        tf_op_layer_add_144[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchN (None, 1, 128, 128,  128         conv3d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_612 (LeakyReLU)     (None, 1, 128, 128,  0           batch_normalization_612[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_145 (Conv3DTra (None, 1, 256, 256,  4624        leaky_re_lu_612[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchN (None, 1, 256, 256,  64          conv3d_transpose_145[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_613 (LeakyReLU)     (None, 1, 256, 256,  0           batch_normalization_613[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_145 (TensorFlow [(None, 1, 256, 256, 0           leaky_re_lu_613[0][0]            \n",
      "                                                                 leaky_re_lu_588[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_468 (Conv3D)             (None, 1, 256, 256,  2320        tf_op_layer_add_145[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchN (None, 1, 256, 256,  64          conv3d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_461 (Conv3D)             (None, 1, 2, 2, 96)  83040       dropout_228[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_614 (LeakyReLU)     (None, 1, 256, 256,  0           batch_normalization_614[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_601 (BatchN (None, 1, 2, 2, 96)  384         conv3d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_146 (Conv3DTra (None, 1, 512, 512,  1160        leaky_re_lu_614[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_601 (LeakyReLU)     (None, 1, 2, 2, 96)  0           batch_normalization_601[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchN (None, 1, 512, 512,  32          conv3d_transpose_146[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_462 (Conv3D)             (None, 1, 2, 2, 96)  83040       leaky_re_lu_601[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_615 (LeakyReLU)     (None, 1, 512, 512,  0           batch_normalization_615[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_602 (BatchN (None, 1, 2, 2, 96)  384         conv3d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_146 (TensorFlow [(None, 1, 512, 512, 0           leaky_re_lu_615[0][0]            \n",
      "                                                                 leaky_re_lu_586[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_602 (LeakyReLU)     (None, 1, 2, 2, 96)  0           batch_normalization_602[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_469 (Conv3D)             (None, 1, 512, 512,  584         tf_op_layer_add_146[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_229 (Dropout)           (None, 1, 2, 2, 96)  0           leaky_re_lu_602[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchN (None, 1, 512, 512,  32          conv3d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, None, 1, 1, 3 0           dropout_229[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_616 (LeakyReLU)     (None, 1, 512, 512,  0           batch_normalization_616[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "msk (InputLayer)                [(None, 1, 512, 512, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pna-cls (Conv3D)                (None, None, 1, 1, 2 770         reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pna-seg (Conv3D)                (None, 1, 512, 512,  146         leaky_re_lu_616[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,266,324\n",
      "Trainable params: 1,262,692\n",
      "Non-trainable params: 3,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.1\n",
    "\n",
    "c1 = conv1(8, inputs['dat'])\n",
    "c2 = conv1(16, conv2(16,c1))\n",
    "c3 = conv1(32, conv2(32,c2))\n",
    "c3_d = layers.Dropout(rate = dropout_rate)(c3)\n",
    "c4 = conv1(48, conv2(48,c3_d))\n",
    "c4_d = layers.Dropout(rate = dropout_rate)(c4)\n",
    "c5 = conv1(64, conv2(64,c4_d))\n",
    "c5_d = layers.Dropout(rate = dropout_rate)(c5)\n",
    "c6 = conv1(96, conv2(96,c5_d))\n",
    "c6_d = layers.Dropout(rate = dropout_rate)(c6)\n",
    "c7 = conv1(96, conv2(96,c6_d))\n",
    "c7_d = layers.Dropout(rate = dropout_rate)(c7)\n",
    "\n",
    "c8 = conv1(96, conv2(96,c7_d))\n",
    "c8_d = layers.Dropout(rate = dropout_rate)(c8)\n",
    "\n",
    "c9 = conv1(96, conv2(96,c8_d))\n",
    "c9_d = layers.Dropout(rate = dropout_rate)(c9)\n",
    "\n",
    "\n",
    "r1 = layers.Reshape((-1,1,1,2*2*96))(c9_d)\n",
    "\n",
    "\n",
    "e1 = tran(96,c8_d)\n",
    "e1_d = layers.Dropout(rate = dropout_rate)(e1)\n",
    "e2 = tran(96, conv1(96, e1_d + c7_d))\n",
    "e2_d = layers.Dropout(rate = dropout_rate)(e2)\n",
    "e3 = tran(64, conv1(96, e2_d + c6_d))\n",
    "e3_d = layers.Dropout(rate = dropout_rate)(e3)\n",
    "e4 = tran(48, conv1(64, e3_d + c5_d))\n",
    "e4_d = layers.Dropout(rate = dropout_rate)(e4)\n",
    "e5 = tran(32, conv1(48, e4_d + c4_d))\n",
    "e5_d = layers.Dropout(rate = dropout_rate)(e5)\n",
    "e6 = tran(16, conv1(32, e5_d + c3_d))\n",
    "e7 = tran(8, conv1(16, e6+c2))\n",
    "e8 = conv1(8, e7+c1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logits = {}\n",
    "\n",
    "logits['pna-seg'] = layers.Conv3D(filters = 2, name = 'pna-seg', **kwargs)(e8)\n",
    "logits['pna-cls'] = layers.Conv3D(2, name = 'pna-cls', kernel_size = (1,1,1))(r1)\n",
    "\n",
    "\n",
    "model = Model(inputs = inputs, outputs = logits)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wiUxI5RmF30t"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "*Hint*: Ensure that custom loss functions are used as described in the tutorial to properly mask the segmentation loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEoiklwMF30u"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
    "    loss={\n",
    "        'pna-seg': custom.sce(inputs['msk']),\n",
    "        'pna-cls': losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    "    metrics={\n",
    "        'pna-seg': custom.dsc(weights=inputs['msk']),\n",
    "        'pna-cls': metrics.SparseCategoricalAccuracy()\n",
    "        },\n",
    "    experimental_run_tf_function=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMIENCI0F30x"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "Use the following cell block to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F0S0VFPaF30y"
   },
   "outputs": [],
   "source": [
    "fname1 = '{}/models/disease_characterization/model_checkpoint.h5'.format(MOUNT_ROOT)\n",
    "check_point = ModelCheckpoint(fname1,monitor='val_pna-cls_sparse_categorical_accuracy',verbose=True, save_best_only=True, save_weights_only=True, mode=\"max\", save_freq=\"epoch\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_pna-cls_sparse_categorical_accuracy', factor=0.2, patience=2, mode = \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 421800,
     "status": "ok",
     "timestamp": 1590701217440,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "oh5inCIO3V2Q",
    "outputId": "ecd8a1a6-90e0-4821-b45e-879797af4b5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.6391 - pna-cls_loss: 0.4180 - pna-seg_loss: 0.2211 - pna-cls_sparse_categorical_accuracy: 0.7959 - pna-seg_dsc_1: 0.2687Epoch 1/20\n",
      "100/50 [============================================================] - 13s 127ms/step - loss: 0.9298 - pna-cls_loss: 0.6916 - pna-seg_loss: 0.2403 - pna-cls_sparse_categorical_accuracy: 0.5325 - pna-seg_dsc_1: 0.3579\n",
      "\n",
      "Epoch 00001: val_pna-cls_sparse_categorical_accuracy improved from -inf to 0.53250, saving model to /content/drive/My Drive/models/disease_characterization/model_checkpoint.h5\n",
      "50/50 [==============================] - 35s 706ms/step - loss: 0.6317 - pna-cls_loss: 0.4123 - pna-seg_loss: 0.2195 - pna-cls_sparse_categorical_accuracy: 0.7975 - pna-seg_dsc_1: 0.2667 - val_loss: 0.9319 - val_pna-cls_loss: 0.6916 - val_pna-seg_loss: 0.2403 - val_pna-cls_sparse_categorical_accuracy: 0.5325 - val_pna-seg_dsc_1: 0.3579\n",
      "Epoch 2/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.2083 - pna-cls_loss: 0.0526 - pna-seg_loss: 0.1557 - pna-cls_sparse_categorical_accuracy: 0.9872 - pna-seg_dsc_1: 0.4188Epoch 1/20\n",
      "100/50 [============================================================] - 11s 109ms/step - loss: 0.9757 - pna-cls_loss: 0.7011 - pna-seg_loss: 0.2225 - pna-cls_sparse_categorical_accuracy: 0.4875 - pna-seg_dsc_1: 0.3270\n",
      "\n",
      "Epoch 00002: val_pna-cls_sparse_categorical_accuracy did not improve from 0.53250\n",
      "50/50 [==============================] - 20s 400ms/step - loss: 0.2074 - pna-cls_loss: 0.0520 - pna-seg_loss: 0.1554 - pna-cls_sparse_categorical_accuracy: 0.9875 - pna-seg_dsc_1: 0.4228 - val_loss: 0.9236 - val_pna-cls_loss: 0.7011 - val_pna-seg_loss: 0.2225 - val_pna-cls_sparse_categorical_accuracy: 0.4875 - val_pna-seg_dsc_1: 0.3270\n",
      "Epoch 3/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.1282 - pna-cls_loss: 0.0161 - pna-seg_loss: 0.1121 - pna-cls_sparse_categorical_accuracy: 0.9949 - pna-seg_dsc_1: 0.5621Epoch 1/20\n",
      "100/50 [============================================================] - 11s 108ms/step - loss: 0.8932 - pna-cls_loss: 0.6632 - pna-seg_loss: 0.2238 - pna-cls_sparse_categorical_accuracy: 0.5275 - pna-seg_dsc_1: 0.2823\n",
      "\n",
      "Epoch 00003: val_pna-cls_sparse_categorical_accuracy did not improve from 0.53250\n",
      "50/50 [==============================] - 20s 398ms/step - loss: 0.1275 - pna-cls_loss: 0.0158 - pna-seg_loss: 0.1116 - pna-cls_sparse_categorical_accuracy: 0.9950 - pna-seg_dsc_1: 0.5671 - val_loss: 0.8870 - val_pna-cls_loss: 0.6632 - val_pna-seg_loss: 0.2238 - val_pna-cls_sparse_categorical_accuracy: 0.5275 - val_pna-seg_dsc_1: 0.2823\n",
      "Epoch 4/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0915 - pna-cls_loss: 0.0103 - pna-seg_loss: 0.0812 - pna-cls_sparse_categorical_accuracy: 0.9974 - pna-seg_dsc_1: 0.6717Epoch 1/20\n",
      "100/50 [============================================================] - 11s 108ms/step - loss: 0.8161 - pna-cls_loss: 0.6005 - pna-seg_loss: 0.2133 - pna-cls_sparse_categorical_accuracy: 0.5987 - pna-seg_dsc_1: 0.1988\n",
      "\n",
      "Epoch 00004: val_pna-cls_sparse_categorical_accuracy improved from 0.53250 to 0.59875, saving model to /content/drive/My Drive/models/disease_characterization/model_checkpoint.h5\n",
      "50/50 [==============================] - 21s 415ms/step - loss: 0.0920 - pna-cls_loss: 0.0102 - pna-seg_loss: 0.0818 - pna-cls_sparse_categorical_accuracy: 0.9975 - pna-seg_dsc_1: 0.6736 - val_loss: 0.8138 - val_pna-cls_loss: 0.6005 - val_pna-seg_loss: 0.2133 - val_pna-cls_sparse_categorical_accuracy: 0.5987 - val_pna-seg_dsc_1: 0.1988\n",
      "Epoch 5/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0825 - pna-cls_loss: 0.0060 - pna-seg_loss: 0.0765 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.6557Epoch 1/20\n",
      "100/50 [============================================================] - 11s 107ms/step - loss: 0.6917 - pna-cls_loss: 0.4587 - pna-seg_loss: 0.2263 - pna-cls_sparse_categorical_accuracy: 0.8700 - pna-seg_dsc_1: 0.2103\n",
      "\n",
      "Epoch 00005: val_pna-cls_sparse_categorical_accuracy improved from 0.59875 to 0.87000, saving model to /content/drive/My Drive/models/disease_characterization/model_checkpoint.h5\n",
      "50/50 [==============================] - 21s 415ms/step - loss: 0.0828 - pna-cls_loss: 0.0061 - pna-seg_loss: 0.0767 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.6585 - val_loss: 0.6850 - val_pna-cls_loss: 0.4587 - val_pna-seg_loss: 0.2263 - val_pna-cls_sparse_categorical_accuracy: 0.8700 - val_pna-seg_dsc_1: 0.2103\n",
      "Epoch 6/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0788 - pna-cls_loss: 0.0035 - pna-seg_loss: 0.0753 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.6625Epoch 1/20\n",
      "100/50 [============================================================] - 11s 108ms/step - loss: 0.6642 - pna-cls_loss: 0.3698 - pna-seg_loss: 0.2377 - pna-cls_sparse_categorical_accuracy: 0.8813 - pna-seg_dsc_1: 0.2410\n",
      "\n",
      "Epoch 00006: val_pna-cls_sparse_categorical_accuracy improved from 0.87000 to 0.88125, saving model to /content/drive/My Drive/models/disease_characterization/model_checkpoint.h5\n",
      "50/50 [==============================] - 21s 418ms/step - loss: 0.0783 - pna-cls_loss: 0.0035 - pna-seg_loss: 0.0749 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.6656 - val_loss: 0.6076 - val_pna-cls_loss: 0.3698 - val_pna-seg_loss: 0.2377 - val_pna-cls_sparse_categorical_accuracy: 0.8813 - val_pna-seg_dsc_1: 0.2410\n",
      "Epoch 7/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0726 - pna-cls_loss: 0.0037 - pna-seg_loss: 0.0689 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7047Epoch 1/20\n",
      "100/50 [============================================================] - 11s 108ms/step - loss: 0.6370 - pna-cls_loss: 0.3333 - pna-seg_loss: 0.2152 - pna-cls_sparse_categorical_accuracy: 0.9087 - pna-seg_dsc_1: 0.4414\n",
      "\n",
      "Epoch 00007: val_pna-cls_sparse_categorical_accuracy improved from 0.88125 to 0.90875, saving model to /content/drive/My Drive/models/disease_characterization/model_checkpoint.h5\n",
      "50/50 [==============================] - 21s 418ms/step - loss: 0.0727 - pna-cls_loss: 0.0037 - pna-seg_loss: 0.0690 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7063 - val_loss: 0.5486 - val_pna-cls_loss: 0.3333 - val_pna-seg_loss: 0.2152 - val_pna-cls_sparse_categorical_accuracy: 0.9087 - val_pna-seg_dsc_1: 0.4414\n",
      "Epoch 8/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0746 - pna-cls_loss: 0.0051 - pna-seg_loss: 0.0695 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.6865Epoch 1/20\n",
      "100/50 [============================================================] - 11s 107ms/step - loss: 0.5153 - pna-cls_loss: 0.3279 - pna-seg_loss: 0.2462 - pna-cls_sparse_categorical_accuracy: 0.9287 - pna-seg_dsc_1: 0.4550\n",
      "\n",
      "Epoch 00008: val_pna-cls_sparse_categorical_accuracy improved from 0.90875 to 0.92875, saving model to /content/drive/My Drive/models/disease_characterization/model_checkpoint.h5\n",
      "50/50 [==============================] - 21s 414ms/step - loss: 0.0750 - pna-cls_loss: 0.0051 - pna-seg_loss: 0.0698 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.6845 - val_loss: 0.5741 - val_pna-cls_loss: 0.3279 - val_pna-seg_loss: 0.2462 - val_pna-cls_sparse_categorical_accuracy: 0.9287 - val_pna-seg_dsc_1: 0.4550\n",
      "Epoch 9/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0723 - pna-cls_loss: 0.0051 - pna-seg_loss: 0.0672 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7100Epoch 1/20\n",
      "100/50 [============================================================] - 11s 108ms/step - loss: 0.6429 - pna-cls_loss: 0.3508 - pna-seg_loss: 0.2402 - pna-cls_sparse_categorical_accuracy: 0.9075 - pna-seg_dsc_1: 0.4682\n",
      "\n",
      "Epoch 00009: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 20s 397ms/step - loss: 0.0727 - pna-cls_loss: 0.0055 - pna-seg_loss: 0.0672 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7084 - val_loss: 0.5910 - val_pna-cls_loss: 0.3508 - val_pna-seg_loss: 0.2402 - val_pna-cls_sparse_categorical_accuracy: 0.9075 - val_pna-seg_dsc_1: 0.4682\n",
      "Epoch 10/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0607 - pna-cls_loss: 0.0041 - pna-seg_loss: 0.0566 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7281Epoch 1/20\n",
      "100/50 [============================================================] - 11s 108ms/step - loss: 0.6643 - pna-cls_loss: 0.3733 - pna-seg_loss: 0.2446 - pna-cls_sparse_categorical_accuracy: 0.9000 - pna-seg_dsc_1: 0.4895\n",
      "\n",
      "Epoch 00010: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 20s 398ms/step - loss: 0.0603 - pna-cls_loss: 0.0040 - pna-seg_loss: 0.0562 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7319 - val_loss: 0.6179 - val_pna-cls_loss: 0.3733 - val_pna-seg_loss: 0.2446 - val_pna-cls_sparse_categorical_accuracy: 0.9000 - val_pna-seg_dsc_1: 0.4895\n",
      "Epoch 11/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0581 - pna-cls_loss: 0.0035 - pna-seg_loss: 0.0546 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7235Epoch 1/20\n",
      "100/50 [============================================================] - 11s 109ms/step - loss: 0.5933 - pna-cls_loss: 0.3973 - pna-seg_loss: 0.2352 - pna-cls_sparse_categorical_accuracy: 0.8875 - pna-seg_dsc_1: 0.5184\n",
      "\n",
      "Epoch 00011: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 0.0595 - pna-cls_loss: 0.0042 - pna-seg_loss: 0.0553 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7253 - val_loss: 0.6324 - val_pna-cls_loss: 0.3973 - val_pna-seg_loss: 0.2352 - val_pna-cls_sparse_categorical_accuracy: 0.8875 - val_pna-seg_dsc_1: 0.5184\n",
      "Epoch 12/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0574 - pna-cls_loss: 0.0019 - pna-seg_loss: 0.0555 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7584Epoch 1/20\n",
      "100/50 [============================================================] - 11s 107ms/step - loss: 0.6249 - pna-cls_loss: 0.4183 - pna-seg_loss: 0.2192 - pna-cls_sparse_categorical_accuracy: 0.8900 - pna-seg_dsc_1: 0.5187\n",
      "\n",
      "Epoch 00012: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 20s 396ms/step - loss: 0.0576 - pna-cls_loss: 0.0018 - pna-seg_loss: 0.0557 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7602 - val_loss: 0.6375 - val_pna-cls_loss: 0.4183 - val_pna-seg_loss: 0.2192 - val_pna-cls_sparse_categorical_accuracy: 0.8900 - val_pna-seg_dsc_1: 0.5187\n",
      "Epoch 13/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0594 - pna-cls_loss: 0.0042 - pna-seg_loss: 0.0552 - pna-cls_sparse_categorical_accuracy: 0.9974 - pna-seg_dsc_1: 0.7558Epoch 1/20\n",
      "100/50 [============================================================] - 11s 107ms/step - loss: 0.7137 - pna-cls_loss: 0.4195 - pna-seg_loss: 0.2225 - pna-cls_sparse_categorical_accuracy: 0.8925 - pna-seg_dsc_1: 0.5330\n",
      "\n",
      "Epoch 00013: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 20s 397ms/step - loss: 0.0591 - pna-cls_loss: 0.0042 - pna-seg_loss: 0.0549 - pna-cls_sparse_categorical_accuracy: 0.9975 - pna-seg_dsc_1: 0.7548 - val_loss: 0.6420 - val_pna-cls_loss: 0.4195 - val_pna-seg_loss: 0.2225 - val_pna-cls_sparse_categorical_accuracy: 0.8925 - val_pna-seg_dsc_1: 0.5330\n",
      "Epoch 14/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0604 - pna-cls_loss: 0.0046 - pna-seg_loss: 0.0557 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7592Epoch 1/20\n",
      "100/50 [============================================================] - 11s 109ms/step - loss: 0.5841 - pna-cls_loss: 0.4471 - pna-seg_loss: 0.2452 - pna-cls_sparse_categorical_accuracy: 0.8800 - pna-seg_dsc_1: 0.5209\n",
      "\n",
      "Epoch 00014: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 0.0599 - pna-cls_loss: 0.0045 - pna-seg_loss: 0.0554 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7485 - val_loss: 0.6923 - val_pna-cls_loss: 0.4471 - val_pna-seg_loss: 0.2452 - val_pna-cls_sparse_categorical_accuracy: 0.8800 - val_pna-seg_dsc_1: 0.5209\n",
      "Epoch 15/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0538 - pna-cls_loss: 0.0023 - pna-seg_loss: 0.0514 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7526Epoch 1/20\n",
      "100/50 [============================================================] - 11s 107ms/step - loss: 0.5423 - pna-cls_loss: 0.4549 - pna-seg_loss: 0.2313 - pna-cls_sparse_categorical_accuracy: 0.8788 - pna-seg_dsc_1: 0.5207\n",
      "\n",
      "Epoch 00015: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 20s 395ms/step - loss: 0.0542 - pna-cls_loss: 0.0025 - pna-seg_loss: 0.0516 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7537 - val_loss: 0.6863 - val_pna-cls_loss: 0.4549 - val_pna-seg_loss: 0.2313 - val_pna-cls_sparse_categorical_accuracy: 0.8788 - val_pna-seg_dsc_1: 0.5207\n",
      "Epoch 16/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0580 - pna-cls_loss: 0.0022 - pna-seg_loss: 0.0557 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7622Epoch 1/20\n",
      "100/50 [============================================================] - 11s 107ms/step - loss: 0.7920 - pna-cls_loss: 0.4469 - pna-seg_loss: 0.2409 - pna-cls_sparse_categorical_accuracy: 0.8725 - pna-seg_dsc_1: 0.5240\n",
      "\n",
      "Epoch 00016: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 20s 398ms/step - loss: 0.0580 - pna-cls_loss: 0.0022 - pna-seg_loss: 0.0558 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7601 - val_loss: 0.6878 - val_pna-cls_loss: 0.4469 - val_pna-seg_loss: 0.2409 - val_pna-cls_sparse_categorical_accuracy: 0.8725 - val_pna-seg_dsc_1: 0.5240\n",
      "Epoch 17/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0637 - pna-cls_loss: 0.0049 - pna-seg_loss: 0.0588 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7522Epoch 1/20\n",
      "100/50 [============================================================] - 12s 115ms/step - loss: 0.6132 - pna-cls_loss: 0.4679 - pna-seg_loss: 0.2503 - pna-cls_sparse_categorical_accuracy: 0.8550 - pna-seg_dsc_1: 0.5114\n",
      "\n",
      "Epoch 00017: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 21s 412ms/step - loss: 0.0631 - pna-cls_loss: 0.0049 - pna-seg_loss: 0.0582 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7508 - val_loss: 0.7182 - val_pna-cls_loss: 0.4679 - val_pna-seg_loss: 0.2503 - val_pna-cls_sparse_categorical_accuracy: 0.8550 - val_pna-seg_dsc_1: 0.5114\n",
      "Epoch 18/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0599 - pna-cls_loss: 0.0036 - pna-seg_loss: 0.0563 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7397Epoch 1/20\n",
      "100/50 [============================================================] - 12s 116ms/step - loss: 0.5456 - pna-cls_loss: 0.4584 - pna-seg_loss: 0.2346 - pna-cls_sparse_categorical_accuracy: 0.8600 - pna-seg_dsc_1: 0.5196\n",
      "\n",
      "Epoch 00018: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 21s 416ms/step - loss: 0.0595 - pna-cls_loss: 0.0036 - pna-seg_loss: 0.0559 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7396 - val_loss: 0.6931 - val_pna-cls_loss: 0.4584 - val_pna-seg_loss: 0.2346 - val_pna-cls_sparse_categorical_accuracy: 0.8600 - val_pna-seg_dsc_1: 0.5196\n",
      "Epoch 19/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0575 - pna-cls_loss: 0.0047 - pna-seg_loss: 0.0527 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7558Epoch 1/20\n",
      "100/50 [============================================================] - 11s 115ms/step - loss: 0.5560 - pna-cls_loss: 0.4555 - pna-seg_loss: 0.2398 - pna-cls_sparse_categorical_accuracy: 0.8600 - pna-seg_dsc_1: 0.5114\n",
      "\n",
      "Epoch 00019: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 21s 414ms/step - loss: 0.0574 - pna-cls_loss: 0.0048 - pna-seg_loss: 0.0526 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7562 - val_loss: 0.6953 - val_pna-cls_loss: 0.4555 - val_pna-seg_loss: 0.2398 - val_pna-cls_sparse_categorical_accuracy: 0.8600 - val_pna-seg_dsc_1: 0.5114\n",
      "Epoch 20/20\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0578 - pna-cls_loss: 0.0045 - pna-seg_loss: 0.0533 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7209Epoch 1/20\n",
      "100/50 [============================================================] - 11s 109ms/step - loss: 0.9350 - pna-cls_loss: 0.4785 - pna-seg_loss: 0.2327 - pna-cls_sparse_categorical_accuracy: 0.8650 - pna-seg_dsc_1: 0.5161\n",
      "\n",
      "Epoch 00020: val_pna-cls_sparse_categorical_accuracy did not improve from 0.92875\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 0.0579 - pna-cls_loss: 0.0045 - pna-seg_loss: 0.0534 - pna-cls_sparse_categorical_accuracy: 1.0000 - pna-seg_dsc_1: 0.7220 - val_loss: 0.7112 - val_pna-cls_loss: 0.4785 - val_pna-seg_loss: 0.2327 - val_pna-cls_sparse_categorical_accuracy: 0.8650 - val_pna-seg_dsc_1: 0.5161\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = gen_train,\n",
    "    steps_per_epoch = 50,\n",
    "    epochs = 20,\n",
    "    validation_data = gen_valid,\n",
    "    validation_steps = 100,\n",
    "    validation_freq = 1,\n",
    "    callbacks = [check_point, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-mFSOF6P7ul"
   },
   "outputs": [],
   "source": [
    "model.load_weights(fname1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOG4d12WF301"
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "Based on the tutorial discussion, use the following cells to calculate model performance. Only model accuracy (global classification performance) needs to evaluated (Dice score does not).\n",
    "\n",
    "### Performance\n",
    "\n",
    "The following minimum performance metrics must be met for full credit:\n",
    "\n",
    "* accuracy: >0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tqoAe2m5F306"
   },
   "source": [
    "### Results\n",
    "\n",
    "When ready, create a `*.csv` file with your compiled **validation** cohort accuracy statistics. There is no need to submit training performance accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6189,
     "status": "ok",
     "timestamp": 1590701336214,
     "user": {
      "displayName": "June Chen",
      "photoUrl": "",
      "userId": "14724189092965811373"
     },
     "user_tz": 420
    },
    "id": "PGQvJTKeF307",
    "outputId": "efc416dd-d226-4910-ef37-897e6c2f6022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-28 21:28:57 ] [====================] 100.000% : Iterating | 000100    0.94\n"
     ]
    }
   ],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for x, y in test_valid:\n",
    "    \n",
    "    # --- Create prediction\n",
    "    logits = model.predict(x)\n",
    "    pred = np.argmax(logits[0], axis=-1)\n",
    "    \n",
    "    # --- Compare with ground truth\n",
    "    accuracy.append(pred.squeeze() == y['pna-cls'].squeeze())\n",
    "\n",
    "accuracy = np.array(accuracy)\n",
    "\n",
    "print(accuracy.mean())\n",
    "df = []\n",
    "df = pd.DataFrame(index=np.arange(accuracy.size))\n",
    "df['accuracy'] = accuracy"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 8.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/peterchang77/dl_tutor/blob/master/cs190/notebooks/disease_characterization/assignment.ipynb",
     "timestamp": 1590615856992
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
